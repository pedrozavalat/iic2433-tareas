{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pontificia Universidad Cat칩lica de Chile <br>\n",
    "Departamento de Ciencia de la Computaci칩n <br>\n",
    "IIC2433 - Miner칤a de Datos\n",
    "<br>\n",
    "\n",
    "<center>\n",
    "    <h2> Tarea 4 </h2>\n",
    "    <h1> MLP y Regresi칩n Log칤stica </h1>\n",
    "    <p>\n",
    "        Profesor Marcelo Mendoza<br>\n",
    "        Segundo Semestre 2023<br>    \n",
    "        Fecha de entrega: 20 de Octubre\n",
    "    </p>\n",
    "    <br>\n",
    "</center>\n",
    "\n",
    "<br>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Indicaciones\n",
    "\n",
    "Deber치s entregar **SOLO** el archivo .ipynb en el buz칩n respectivo en canvas.\n",
    "\n",
    "**IMPORTANTE**:\n",
    "- Se te dar치 puntaje tanto por c칩digo como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un c칩digo perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendr치 el puntaje completo.\n",
    "- El notebook debe tener todas las celdas de c칩digo ejecutadas. Cualquier notebook que no las tenga no podr치 ser corregido.\n",
    "- El car치cter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultar치 en un 1,1 como nota de curso.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librer칤as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuaci칩n se encuentran las librer칤as necesarias para elaborar la tarea. Recuerda ejecutar la celda antes de comenzar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 868,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.utils import to_categorical # .\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "from keras.models import Sequential # .\n",
    "from keras.layers import Dense # .\n",
    "from keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from typing import List\n",
    "# import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import itertools\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contexto: C치ncer de mama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Octubre es dedicado como el \"Mes de la Sensibilizaci칩n sobre el C치ncer de Mama\". Este tipo de c치ncer afecta a millones de personas en el mundo, y a pesar de los avances m칠dicos y campa침as de sensibilizaci칩n, sigue siendo una de las principales causas de muerte en mujeres.Uno de los desaf칤os m치s significativos es que, en muchos casos, el c치ncer de mama no presenta s칤ntomas evidentes en sus etapas iniciales. Esto significa que la detecci칩n temprana a trav칠s de ex치menes regulares y la autoexploraci칩n mamaria son cruciales para mejorar las tasas de supervivencia y reducir la gravedad de la enfermedad en el momento del diagn칩stico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "En el 치mbito de la miner칤a de datos, las herramientas y t칠cnicas que se ense침an en este curso adquieren un valor excepcional en el campo de la salud, especialmente en lo que respecta a la detecci칩n de enfermedades. La miner칤a de datos ofrece una poderosa capacidad para analizar grandes conjuntos de informaci칩n m칠dica, identificar patrones y tendencias ocultas, y desarrollar modelos predictivos precisos. Por lo tanto, deseamos destacar la utilidad de los conocimientos y modelos que se adquieren en este curso, ya que tienen un impacto real y significativo en la ciencia m칠dica.\n",
    "\n",
    "Gracias a la aplicaci칩n de la miner칤a de datos, podemos mejorar sustancialmente la eficiencia de la detecci칩n de enfermedades. Esto significa que podemos identificar se침ales tempranas de enfermedades, realizar diagn칩sticos m치s precisos y predecir la progresi칩n de condiciones m칠dicas. En 칰ltima instancia, esta capacidad tiene el potencial de salvar vidas al permitir intervenciones m칠dicas m치s oportunas y efectivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus (3 puntos) 游댠\n",
    "\n",
    "Al momento de escribir codigo es importante asegurarnos de que tanto nosotros como otras personas seran capaces de entenderlo. Con este fin, se utilizan diferentes medios como por ejemplo los comentarios al momento de implementar, docstrings para metodos, clases y modulos, type-hinting, entre otros. Debido a lo importante de esto, es que en esta tarea se otorgara un bonus de 3 puntos por el correcto uso de type-hinting al momento de declarar variables y funciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 1: Carga y Preprocesamiento de Datos (10 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esta tarea, deber치s utilizar el dataset [Breast Cancer Wisconsin](https://www.kaggle.com/datasets/uciml/breast-cancer-wisconsin-data) que se puede encontrar en Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Carga de Datos (1 Pts.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos los datos en la varible data\n",
    "data = pd.read_csv('breast_cancer_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Descripci칩n del Dataset (3 Pts.)\n",
    "A continuaci칩n, presenta una descripci칩n detallada del dataset. Se espera que investigues los datos, y expliques en que consisten al menos 9 columnas. Dentro de la explicaci칩n, menciona a qu칠 tipo de datos corresponde cada columna. 쮺u치l es la columna objetivo? 쯈u칠 significa cada valor de esta columna?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "      <th>Unnamed: 32</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>842302</td>\n",
       "      <td>M</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.3001</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.1622</td>\n",
       "      <td>0.6656</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>842517</td>\n",
       "      <td>M</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.1238</td>\n",
       "      <td>0.1866</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>84300903</td>\n",
       "      <td>M</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.1974</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.1444</td>\n",
       "      <td>0.4245</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>84348301</td>\n",
       "      <td>M</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.2414</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.2098</td>\n",
       "      <td>0.8663</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84358402</td>\n",
       "      <td>M</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.1980</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.2050</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows 칑 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         id diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0    842302         M        17.99         10.38          122.80     1001.0   \n",
       "1    842517         M        20.57         17.77          132.90     1326.0   \n",
       "2  84300903         M        19.69         21.25          130.00     1203.0   \n",
       "3  84348301         M        11.42         20.38           77.58      386.1   \n",
       "4  84358402         M        20.29         14.34          135.10     1297.0   \n",
       "\n",
       "   smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0          0.11840           0.27760          0.3001              0.14710   \n",
       "1          0.08474           0.07864          0.0869              0.07017   \n",
       "2          0.10960           0.15990          0.1974              0.12790   \n",
       "3          0.14250           0.28390          0.2414              0.10520   \n",
       "4          0.10030           0.13280          0.1980              0.10430   \n",
       "\n",
       "   ...  texture_worst  perimeter_worst  area_worst  smoothness_worst  \\\n",
       "0  ...          17.33           184.60      2019.0            0.1622   \n",
       "1  ...          23.41           158.80      1956.0            0.1238   \n",
       "2  ...          25.53           152.50      1709.0            0.1444   \n",
       "3  ...          26.50            98.87       567.7            0.2098   \n",
       "4  ...          16.67           152.20      1575.0            0.1374   \n",
       "\n",
       "   compactness_worst  concavity_worst  concave points_worst  symmetry_worst  \\\n",
       "0             0.6656           0.7119                0.2654          0.4601   \n",
       "1             0.1866           0.2416                0.1860          0.2750   \n",
       "2             0.4245           0.4504                0.2430          0.3613   \n",
       "3             0.8663           0.6869                0.2575          0.6638   \n",
       "4             0.2050           0.4000                0.1625          0.2364   \n",
       "\n",
       "   fractal_dimension_worst  Unnamed: 32  \n",
       "0                  0.11890          NaN  \n",
       "1                  0.08902          NaN  \n",
       "2                  0.08758          NaN  \n",
       "3                  0.17300          NaN  \n",
       "4                  0.07678          NaN  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 870,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(n=5) # Mostramos las primeras 5 columnas del dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "游녤游낕 El dataSet contiene las caracteristicas a partir de imagenes digitalizadas de una puncion aspirativa con aguja fina PAAF$^1$ de una masa mamaria. Estas caracteristicas describen al nucleo celular presente en la imagen. \n",
    "\n",
    "游녤游낕 Cada fila del ```dataset``` corresponde a las caracteristicas de la imagen digitalizada de la masa mamaria. En ella podemos encontrar las siguientes caracteristicas: \n",
    "\n",
    "* **id**: Numero ID de la imagen digitalizada. Corresponde a una variable de numerica y el valor es de tipo entero. \n",
    "* **Diagnosis**: Car치cter M o B, el cual hace referencia si el diagnosis del tejido mamario fue diagnosticada con un tumor benigno (las celulas no son cancer칤genas), o maligno (las celulas son cancer칤genas). Corresponde a una variable de tipo categorica, y el valor es de tipo texto.\n",
    "Las siguientes caracteristicas son variables de tipo continuas en donde el valor que presentan es de tipo decimal:\n",
    "* **radius**: Distancia promedio formada entre los puntos que se encuentran entre el perimetro hasta el centro del nucleo celular. \n",
    "* **perimeter_mean**: Tama침o promedio del tumor central de la imagen. \n",
    "* **area_mean**: Area promedio del tumor central de la imagen. \n",
    "* **radius_se**: Error estandar del promedio de las distancias desde el centro hasta los puntos del perimetro del tumor central de la imagen. \n",
    "* **radius_worst**: el valor promedio mas grande de los valores de las distancias promedio desde el punto central hasta los puntos del perimetro del tumor presente en la imagen. \n",
    "* **symmetry_mean**: Dentro del area especializada en la clasificacion de tumores cancerigenos, cuando nos referimos a la simetria de un tumor se basa en que tan regular o irregular es la forma del tumor. Dentro del contexto del dataset, el atributo \"Simestria promedio\" se refiere a la forma del tumor central de la imagen $^2$, es decir, cuantifica que tan irregular o simetrico es la forma del tumor en la imagen. \n",
    "* **area_se**: Error estandar del area promedio del tumor central de la imagen. \n",
    "\n",
    "游녤游낕 Nuestra variable objetivo sera la caracteristica **diagnosis**, dado que nos permitira verificar el nivel de prediccion de nuestro modelo a implementar. Sera nuestra variable de respuesta ante los niveles de prediccion considerando las caracteristicas restantes del dataset. Como comentamos anteriormente, cada valor de la columna diagnosis corresponde a la clasificacion del tumor presentado en la imagen digitalizada. Este columna presenta dos valores: M y B, cuyo significado es si el tumor es maligno o benigno, respectivamente. \n",
    "\n",
    "\n",
    "$^{1\\text{ M칠todo diagn칩stico basado en la obtenci칩n de material citol칩gico procedente de un n칩dulo o tumoraci칩n, para luego estudiarlo microsc칩picamente (Elsevier, 2008)}}$ [Link](https://www.elsevier.es/es-revista-anales-pediatria-continuada-51-articulo-puncion-aspirativa-con-aguja-fina-S1696281808748819)\n",
    "\n",
    "$^{2 \\text{ Clasificacion de la simetria o irregularidad de la forma de un tumor}}$ [Link](https://www.mdpi.com/2073-8994/15/3/571)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Limpieza del set de datos (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En esta secci칩n, deber치s revisar el dataset y hacer una limpieza de los datos. Esto significa que deber치s tratar posibles `datos nulos, outliers, columnas innecesarias`, etc. 游븷 Adem치s, es importante que utilices One Hot Encoding para el diagn칩stico, dejando 0 a las muestras benignas y 1 a las malignas.\n",
    "\n",
    "**IMPORTANTE:** m치s all치 del c칩digo, lo m치s importante aqu칤 es `explicar` lo que est치s haciendo, las decisiones para limpiar que tomas y sobre todo `justificar`. Hay libertad en cuanto a lo que se puede hacer, pero es **importante** que se justifique cualquier procedimiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {},
   "outputs": [],
   "source": [
    "# En primer lugar eliminaremos la ultima columna \"Unnamed: 32\", la cual solo contiene valores nulos en el dataset\n",
    "data = data.drop(['Unnamed: 32'], axis=1)\n",
    "# Por otra parte, eliminaremos la columna ID de cada imagen, ya que para este caso no es una caracteristica que \n",
    "# describa numericamente las cualidades/caracteristicas del tumor de la imagen. Solo la guardaremos por si es que la utilizamos en un futuro. \n",
    "id_column = data['id']\n",
    "data = data.drop(['id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows 칑 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [diagnosis, radius_mean, texture_mean, perimeter_mean, area_mean, smoothness_mean, compactness_mean, concavity_mean, concave points_mean, symmetry_mean, fractal_dimension_mean, radius_se, texture_se, perimeter_se, area_se, smoothness_se, compactness_se, concavity_se, concave points_se, symmetry_se, fractal_dimension_se, radius_worst, texture_worst, perimeter_worst, area_worst, smoothness_worst, compactness_worst, concavity_worst, concave points_worst, symmetry_worst, fractal_dimension_worst]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 31 columns]"
      ]
     },
     "execution_count": 872,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Luego verificaremos si el dataset contiene datos nulos. En el caso que si, eliminamos las filas correspondientes. \n",
    "data[data.isnull().any(axis=1)]\n",
    "\n",
    "# Notamos que no existen filas nulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>diagnosis</th>\n",
       "      <th>radius_mean</th>\n",
       "      <th>texture_mean</th>\n",
       "      <th>perimeter_mean</th>\n",
       "      <th>area_mean</th>\n",
       "      <th>smoothness_mean</th>\n",
       "      <th>compactness_mean</th>\n",
       "      <th>concavity_mean</th>\n",
       "      <th>concave points_mean</th>\n",
       "      <th>symmetry_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>radius_worst</th>\n",
       "      <th>texture_worst</th>\n",
       "      <th>perimeter_worst</th>\n",
       "      <th>area_worst</th>\n",
       "      <th>smoothness_worst</th>\n",
       "      <th>compactness_worst</th>\n",
       "      <th>concavity_worst</th>\n",
       "      <th>concave points_worst</th>\n",
       "      <th>symmetry_worst</th>\n",
       "      <th>fractal_dimension_worst</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>...</td>\n",
       "      <td>25.380</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>...</td>\n",
       "      <td>24.990</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>...</td>\n",
       "      <td>23.570</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>...</td>\n",
       "      <td>14.910</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>...</td>\n",
       "      <td>22.540</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>1</td>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>...</td>\n",
       "      <td>25.450</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>1</td>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>...</td>\n",
       "      <td>23.690</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>1</td>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>...</td>\n",
       "      <td>18.980</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>1</td>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>...</td>\n",
       "      <td>25.740</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>0</td>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>...</td>\n",
       "      <td>9.456</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows 칑 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     diagnosis  radius_mean  texture_mean  perimeter_mean  area_mean  \\\n",
       "0            1        17.99         10.38          122.80     1001.0   \n",
       "1            1        20.57         17.77          132.90     1326.0   \n",
       "2            1        19.69         21.25          130.00     1203.0   \n",
       "3            1        11.42         20.38           77.58      386.1   \n",
       "4            1        20.29         14.34          135.10     1297.0   \n",
       "..         ...          ...           ...             ...        ...   \n",
       "564          1        21.56         22.39          142.00     1479.0   \n",
       "565          1        20.13         28.25          131.20     1261.0   \n",
       "566          1        16.60         28.08          108.30      858.1   \n",
       "567          1        20.60         29.33          140.10     1265.0   \n",
       "568          0         7.76         24.54           47.92      181.0   \n",
       "\n",
       "     smoothness_mean  compactness_mean  concavity_mean  concave points_mean  \\\n",
       "0            0.11840           0.27760         0.30010              0.14710   \n",
       "1            0.08474           0.07864         0.08690              0.07017   \n",
       "2            0.10960           0.15990         0.19740              0.12790   \n",
       "3            0.14250           0.28390         0.24140              0.10520   \n",
       "4            0.10030           0.13280         0.19800              0.10430   \n",
       "..               ...               ...             ...                  ...   \n",
       "564          0.11100           0.11590         0.24390              0.13890   \n",
       "565          0.09780           0.10340         0.14400              0.09791   \n",
       "566          0.08455           0.10230         0.09251              0.05302   \n",
       "567          0.11780           0.27700         0.35140              0.15200   \n",
       "568          0.05263           0.04362         0.00000              0.00000   \n",
       "\n",
       "     symmetry_mean  ...  radius_worst  texture_worst  perimeter_worst  \\\n",
       "0           0.2419  ...        25.380          17.33           184.60   \n",
       "1           0.1812  ...        24.990          23.41           158.80   \n",
       "2           0.2069  ...        23.570          25.53           152.50   \n",
       "3           0.2597  ...        14.910          26.50            98.87   \n",
       "4           0.1809  ...        22.540          16.67           152.20   \n",
       "..             ...  ...           ...            ...              ...   \n",
       "564         0.1726  ...        25.450          26.40           166.10   \n",
       "565         0.1752  ...        23.690          38.25           155.00   \n",
       "566         0.1590  ...        18.980          34.12           126.70   \n",
       "567         0.2397  ...        25.740          39.42           184.60   \n",
       "568         0.1587  ...         9.456          30.37            59.16   \n",
       "\n",
       "     area_worst  smoothness_worst  compactness_worst  concavity_worst  \\\n",
       "0        2019.0           0.16220            0.66560           0.7119   \n",
       "1        1956.0           0.12380            0.18660           0.2416   \n",
       "2        1709.0           0.14440            0.42450           0.4504   \n",
       "3         567.7           0.20980            0.86630           0.6869   \n",
       "4        1575.0           0.13740            0.20500           0.4000   \n",
       "..          ...               ...                ...              ...   \n",
       "564      2027.0           0.14100            0.21130           0.4107   \n",
       "565      1731.0           0.11660            0.19220           0.3215   \n",
       "566      1124.0           0.11390            0.30940           0.3403   \n",
       "567      1821.0           0.16500            0.86810           0.9387   \n",
       "568       268.6           0.08996            0.06444           0.0000   \n",
       "\n",
       "     concave points_worst  symmetry_worst  fractal_dimension_worst  \n",
       "0                  0.2654          0.4601                  0.11890  \n",
       "1                  0.1860          0.2750                  0.08902  \n",
       "2                  0.2430          0.3613                  0.08758  \n",
       "3                  0.2575          0.6638                  0.17300  \n",
       "4                  0.1625          0.2364                  0.07678  \n",
       "..                    ...             ...                      ...  \n",
       "564                0.2216          0.2060                  0.07115  \n",
       "565                0.1628          0.2572                  0.06637  \n",
       "566                0.1418          0.2218                  0.07820  \n",
       "567                0.2650          0.4087                  0.12400  \n",
       "568                0.0000          0.2871                  0.07039  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 873,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ahora cambiaremos el tipo atributo diagnosis a una variable de tipo cualitativa binaria, es decir, \n",
    "# utilizaremos one hot encodding para el diagnostico: B = 0 y M = 1\n",
    "data['diagnosis'] = data['diagnosis'].replace('B', 0)\n",
    "data['diagnosis'] = data['diagnosis'].replace('M', 1)\n",
    "data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "游늷 En este caso implementamos deteccion de outliers usando LOF, ya que nos permite eliminar los outliers del dataset de manera directa. Solo consideramos los datos mas agrupados (inliners), mientras que los outliers son eliminados del dataset. Asi presentamos nos permite evitar la redundancia y presentar mejoras al momento de realizar predicciones. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(569, 6)"
      ]
     },
     "execution_count": 874,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente eliminaremos los outliers del dataset detectandolos utilizando LOF para k = 5.\n",
    "\n",
    "# Primero normalizaremos el data mediante MinMax Scaler para verificar el umbral del corte\n",
    "data_scaled = MinMaxScaler().fit_transform(data.values)\n",
    "\n",
    "# Luego reducimos la dimensionalidad de data_normalized con un 90% de varianza retenida\n",
    "pca = PCA(0.90, whiten=True)\n",
    "data_pca = pca.fit_transform(data_scaled)\n",
    "data_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego de haber reducido la dimensionalidad a 6 componentes, obtenemos el umbral de corte \n",
    "# con 5 vecinos cercanos para cada dato\n",
    "lof = LocalOutlierFactor(n_neighbors=5, metric='euclidean')\n",
    "lof.fit_predict(data_pca)\n",
    "scores = lof.negative_outlier_factor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_hist(X: pd.DataFrame, title: str) -> None:\n",
    "    \"\"\" Funcion que genera un grafico de los valores de LOF del dataset \"\"\"\n",
    "    x, bins, patches = plt.hist(x=X, bins='auto', rwidth=0.85, color='darkred')\n",
    "    plt.grid(axis='y')\n",
    "    plt.xlabel('LOF')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title(title)\n",
    "    maxfreq = x.max()\n",
    "    plt.ylim(ymax=np.ceil(maxfreq))\n",
    "    \n",
    "plot_hist(scores, 'LOF')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.008787346221441126"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dado el grafico anterior, diremos que un umbral de corte sera aproximadamente -1.85\n",
    "def lof_threshold(v: float, scores: np.ndarray) -> float:\n",
    "    ''' Retorna la contaminacion del medio '''\n",
    "    N = len(scores)\n",
    "    points = scores[scores < v]\n",
    "    threshold = len(points)/N\n",
    "    return threshold \n",
    "\n",
    "lof_threshold(-1.85,scores) # Contaminacion del medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos que la contaminacion del medio es de un 0.0070298767 aproximadamente, y\n",
    "lof = LocalOutlierFactor(n_neighbors=5, metric='euclidean', contamination=0.00878734622)\n",
    "labels = lof.fit_predict(data_pca)\n",
    "\n",
    "# Obtenemos los indices de los datos que son inliners\n",
    "indices = list(np.where(labels==1)[0])\n",
    "\n",
    "# Eliminamos los outliers del dataset 'data', filtrando el dataset solo con los datos\n",
    "# que no son inliners (label = 1)\n",
    "data_without_outliers = data.values[indices,:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 203, 212, 461, 491]\n"
     ]
    }
   ],
   "source": [
    "print(list(np.where(labels==-1)[0])) # Podemos ver que tenemos solamente 5 outliners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anterior: (569, 31), Actual: (564, 31)\n"
     ]
    }
   ],
   "source": [
    "# Ahora podemos visualizar el data anterior y el actual, tal que el actual no presenta los 5 outliers. \n",
    "print(f'Anterior: {data.shape}, Actual: {data_without_outliers.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        842302\n",
       "1        842517\n",
       "2      84300903\n",
       "4      84358402\n",
       "5        843786\n",
       "         ...   \n",
       "564      926424\n",
       "565      926682\n",
       "566      926954\n",
       "567      927241\n",
       "568       92751\n",
       "Name: id, Length: 564, dtype: int64"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Tambien, eliminaremos las imagenes que tambien corresponden a outliers\n",
    "id_column[indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Normalizaci칩n de datos (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normaliza los datos y responde las preguntas:\n",
    "1. 쯇or qu칠 es necesario normalizar los datos?\n",
    "2. 쯈u칠 tipo de normalizaci칩n se utiliz칩? 쯇or qu칠?\n",
    "3. 쯈u칠 columnas se normalizaron? 쯇or qu칠?\n",
    "4. Explique la diferencia entre el uso de `standard scaler` y `minmax scaler` como estrategia para normalizar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Antes de normalizar, verificaremos el rango de valores para cada atributo e identificaremos\n",
    "# cuales son las caracteristicas que presentan rangos de valores fuera de [0,1]\n",
    "def get_columns_with_range_out_of_0_1(data: pd.DataFrame) -> List[str]:\n",
    "    ''' Retorna las columnas donde el rango de valores no esta en [0,1] '''\n",
    "    columns = []\n",
    "    for i in range(data.shape[1]):\n",
    "        if data[data.columns[i]].max() > 1 or data[data.columns[i]].min() > 1:\n",
    "            columns.append(i)\n",
    "    return columns\n",
    "\n",
    "# Obtenemos los indices de las caracteristicas que presentan valores fuera de [0,1]\n",
    "columns_index_with_range_out_0_1 = get_columns_with_range_out_of_0_1(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Realizamos un escalamiento de los datos dentro de un intervalo [0,1]\n",
    "# Solo realizaremos un escalamiento de las columnas que no presentan datos que oscilan entre 0 y 1. \n",
    "scaler = MinMaxScaler()\n",
    "data_without_outliers[:, columns_index_with_range_out_0_1] = scaler.fit_transform(data_without_outliers[:, columns_index_with_range_out_0_1])\n",
    "\n",
    "# Redefinimos el dataset \n",
    "X_scaled = data_without_outliers "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Normalizar los datos nos permite tener mejores resultados al momento de realizar predicciones. Ademas, evitamos la redundancia de datos y establecemos margen general de valores para todos los datos tal que no se presenta una gran dispersion entre ellos.\n",
    "\n",
    "2. Utilice el tipo de normalizacion ```MinMaxScaler```, ya que nos permite establecer todos los valores dentro de un mismo rango que varia entre 0 y 1, inclusive. Esto fue realizado, dado que nos permite asegurarnos que los datos estend entro de un intervalo fijo y no obtener grandes variaciones de valores entre ellos. Ademas, tener valores que oscilen entre 0 y 1 es mas comodo para modelos que presentan predicciones mediante estrategias probabilisticas. \n",
    "\n",
    "3. Normalice solo las columnas que presentan valores que no estan dentro del rango [0,1]. En este caso, son solos las columnas con indices en ```columns_index_with_range_out_0_1```. Esto nos permite mantener los valores originales de las caracteristicas ya con valores entre 0 y 1, y adecuar los valores que no estan dentro de la misma escala. \n",
    "\n",
    "4. *StandardScaler* es un tipo de normalizacion que transforma cada dato centrado entorno a la media, mientras que MinMaxScaler, o conocido como *Scaling*, establece cada dato dentro del intervalo [0,1]. Como estrategia para normalizar, StandardScaler funciona correctamente cuando los datos se distribuyen de manera normal. A diferencia de Scaling, esta preserva de mejor manera la distancia entre los puntos y es menos sensible frente a la presencia de outliers. Mientras que para MinMaxScaler, transforma cada dato en una probabilidad. No retiene de la mejor manera las distancias entre cada dato. Es mas sensible frente a la presencia de outliers. Y tambien, es mas preferible de usar cuando no se tiene conocimiento de la forma en que se distribuyen los datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Partici칩n training/testing (0 Pts.)\n",
    "Cree particiones de training/testing con test_size=0.3. Recuerda recuperar la variable objetivo \"y\" del dataset y `separarla` de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 884,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos la variable objetivo sin outliers y la eliminamos del dataset:\n",
    "y = X_scaled[:, 0] # Atributo 'diagnosis'\n",
    "\n",
    "# Eliminamos el atributo 'diagnosis' del dataset\n",
    "X_scaled = np.delete(X_scaled, 0, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 885,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Luego creamos las particiones de training/testing con test_size = 0.3\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.3) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 2: Perceptron y Multi Layer Perceptr칩n (25 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Perceptron (5 Pts.)\n",
    "Investigue sobre `Perceptron`游뱄 y de una explicaci칩n de c칩mo funciona. `No es necesaria una explicaci칩n matem치tica`, el objetivo es que puedas tomar lo que aprendiste en clases o buscando en internet, y logres exponerlo de manera sintetizada para `demostrar tu aprendizaje` 游. Se espera que tu explicaci칩n contenga la respuesta a las siguientes preguntas: 쯈u칠 es? 쯇ara qu칠 sirve? 쮺칩mo funciona? 쮺u치les son sus ventajas y desventajas? 쮼n qu칠 situaciones se puede utilizar? 쯈u칠 tipo de problemas puede resolver? 쯈u칠 son los pesos y funci칩n de activaci칩n? 쮺u치les son las limitaciones del modelo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__쯈u칠 es?__ \n",
    "\n",
    "游녤游낕 Perceptron es un modelo lineal que tiene la principal finalidad de clasificar los datos dentro de un espacio n-dimensional ($n\\geq1$) a partir del uso de un hiperplano. Se conoce principalmente por ser un modelo de red neuronal, cuyo modelo implementado realiza una separacion lineal de los datos, clasificandolos binariamente a partir de una variable objetivo $y$. \n",
    "\n",
    "\n",
    "__쮺칩mo funciona?__ __쯈u칠 son los pesos y funci칩n de activaci칩n?__ \n",
    "\n",
    "\n",
    "游녤游낕 Como mencionamos, perceptron es un modelo de red neuronal que permite clasificar los datos de manera binaria. Este modelo esta formado por diferentes componentes al momento de clasificar. \n",
    "<figure style=\"text-align:center;\">\n",
    "  <img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/b/b0/Perceptr%C3%B3n_5_unidades.svg/800px-Perceptr%C3%B3n_5_unidades.svg.png\">\n",
    "  <figcaption style=\"font-size:smaller;text-align:center;\">Fuente: Wikipedia</figcaption>\n",
    "</figure>\n",
    "\n",
    "* Recibe las variables de entradas, las cuales representan el vector de caracteristicas $\\textbf{x} = [\\textbf{x}_1, \\dots,\\textbf{x}_N]$. \n",
    "* Para cada variable de entrada le asigna un peso, el cual corresponde a un parametro del modelo que representa \"la influencia o que tan util\" es una caracteristica. Estos coeficientes se ajustan en cada iteracion del algoritmo. \n",
    "* El algoritmo de perceptron aplica la funcion de activacion $h$ signo sobre la suma de las combinaciones lineales entre el vector de caracteristica y el vector de los pesos de cada variable. \n",
    "        $$h(\\textbf{x}) = \\text{sign}{(\\textbf{w}^T \\textbf{x})}$$\n",
    "        Esta funcion de activacion permite tomar la decision al momento de clasificar cada dato dentro de una variable categorica, retornando +1 en el caso de que corresponda correctamente a la clase objetivo, o -1 en el otro caso que no cumpla esta clasificacion. La combinacion lineal $\\textbf{w}^T\\textbf{x}$ es mas que nada el hiperplano formado dentro del espacio n-dimensional. El objetivo de perceptron es encontrar el hiperplano optimo que permita separar \"exactamente\" los datos, de manera que estos sean clasificados correspondiente a una clase u otra segun el valor retornado de la funcion de activacion. Este algoritmo actualiza en cada iteracion los valores de los pesos de $\\textbf{w}$, con el fin de que el vector $\\textbf{w}$ se acerca al vector de las variables de entradas mal clasificadas para el caso de que $y=+1$, o se aleja de este vector para $y=-1$. \n",
    "* Los valores de salida permiten evaluar la clasificacion de cada dato. En este caso, presentamos una variable objetivo binaria $y=\\{+1,-1\\}$. El objetivo de perceptron es estimar esta variable objetivo a partir de la clasificacion binaria de cada dato. \n",
    "\n",
    "__쮺u치les son sus ventajas y desventajas?__\n",
    "\n",
    "游녤游낕 Las principales ventajas que presenta Perceptron es su implementacion y complejidad. Dado que solo necesitamos un hiperplano para poder clasificar los datos en dos agrupaciones distintas, nos permite entender e interpretar de mejor forma los resultados del modelo. En ese sentido, es facil de implementar para problemas en donde se pueden separar los datos de manera lineal a partir de su interpretacion geometrica. Sin embargo, en consecuencia presenta desventajas tambien en el caso que presentemos datos que no se pueden separar de manera lineal. Puede ser el caso en que existan datos que tengan un alto grado de similitud, por lo que una linea recta no va a poder clasificar de manera binaria estos datos correctamente, es decir, presenta una baja capacidad de generalizacion.\n",
    "\n",
    "__쮺u치les son las limitaciones del modelo?__\n",
    "\n",
    "游녤游낕 Como habiamos descrito una de las principales limitaciones del modelo es su capacidad de generalizacion, es decir,  Perceptron simple solo puede separar datos aplicando funciones lineales, por lo que no podra clasificar correctamente datos que no son linealmente separables ya que el algoritmo no podra aprender de una funcion que los clasifica de manera incorrecta. \n",
    "\n",
    "__쯇ara qu칠 sirve?__  __쮼n qu칠 situaciones se puede utilizar?__ __쯈u칠 tipo de problemas puede resolver?__ \n",
    "\n",
    "游녤游낕 Perceptron es principalmente util para problemas de clasificacion binaria, en donde se asigna/clasifica cada dato de un dataset el valor de una variable categorica. \n",
    "\n",
    "游녤游낕 La aplicacion de redes neuronales es principalmente util en diferentes areas de las ciencias como: Noticias; Ciencias de la salud; robotica; Politica, entre otros. \n",
    "\n",
    "游녤游낕 Es decir, perceptron solo se podria usar para problemas de clasificacion binaria que permite separar los datos linealmente, utilizando funciones lineales (que no presentan una alta complejidad). Algunos de los tipos de problemas que se pueden resolver con perceptron (siempre y cuando los datos sean linealmente separables) pueden ser como: Clasificar mensajes que son toxicos y no toxicos; Clasificacion de imagenes, entre otros. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Referencias\n",
    "- [GamCo - Perceptron definicion](https://gamco.es/glosario/perceptron/)\n",
    "- [AprendeIA - Que es perceptron simple y multicapa](https://aprendeia.com/que-es-el-perceptron-simple-y-multicapa/)\n",
    "- [Blog Damavis - Perceptron, definicion matematica y propiedades](https://blog.damavis.com/perceptron-simple-definicion-matematica-y-propiedades/)\n",
    "- [Linkedin - Advantages and Disadvantages usin single layer](https://www.linkedin.com/advice/0/what-advantages-disadvantages-using-single-layer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Multi Layer Perceptron (5 Pts.)\n",
    "Ahora debes investigar sobre `Multi Layer Perceptron (MLP)` y nuevamente explicar con tus propias palabras c칩mo funciona. Debes poner 칠nfasis en las principales diferencias y cambios que tiene con respecto al `Perceptron`. Agrega en tu desarrollo la respuesta a la siguiente pregunta: 쯇or qu칠 es conveniente utilizar MLP para el dataset presentado en esta tarea?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__쯈ue es?__\n",
    "\n",
    "游녤游낕 Multi Layer Perceptron es un modelo de redes neuronales construido por multicapas (e.g una coleccion de Perceptrones). Tiene como objetivo clasificar patrones en problemas donde no se permite una clasificacion solamente utilizando funciones con complejidad lineal (e.g. datos no linealmente separables). La estructura de las redes neuronales contiene 3 capas principales: _input layer_, _hidden layer_, y _output layer_. \n",
    "<figure style=\"display: block; margin-left: 10cm; margin-right: auto; text-align: center;\">\n",
    "  <img src=\"https://rasbt.github.io/mlxtend/user_guide/classifier/NeuralNetMLP_files/neuralnet_mlp_1.png\">\n",
    "  <figcaption style=\"font-size:smaller;text-align:center;\">Fuente: mlxtend - MLP</figcaption>\n",
    "</figure>\n",
    "\n",
    "Estas capas presentan distintos propositos entre si: \n",
    "\n",
    "1. __input layer__: Recibe las variables de entrada \n",
    "2. __hidden layer__: Una o mas capas de redes neuronales que estan entre las capas input y output, cuyo proposito es aplicar funciones no lineales dentro del procesamiento de la informacion recibida por la capa _input_, y permiten al modelo MLP aprender problemas complejos. \n",
    "3. __output layer__: Capa en donde se retorna el resultado final a partir de la data procesada a trav칠s de la capa oculta (_hidden layer_). \n",
    "\n",
    "__쮺uales son las principales diferencias con respecto a ```Perceptron```?__\n",
    "\n",
    "游녤游낕 Una de las principales diferencias con entre MLP y Perceptron es que el primero aprende de los datos aplicando funciones no lineales, mientras que el segundo solo puede aprender de los datos si estos son linealmente separables (e.g. aplicando funciones de complejidad lineal). Es por ello que ambos modelos estan enfocados a resolver problemas con diferente complejidad. En el caso de Perceptron, esta implementado para resolver problemas simples, en donde solo se requiere como resultado una clasificacion binaria de una variable categorica para cada dato. Mientras que MLP puede ser utilizado para problemas con mayor complejidad. \n",
    "\n",
    "__쯈ue tipos de problemas resuelve?__\n",
    "\n",
    "游녤游낕 El modelo Multi Layer Perceptron puede ser aplicado en diferentes problemas, como por ejemplo: reconocimiento de patrones; optimizacion; prediccion, y entre otros.\n",
    "\n",
    "__쯇or qu칠 es conveniente utilizar MLP para el dataset presentado en esta tarea?__\n",
    "\n",
    "游녤游낕 Mi hipotesis de por que es conveniente usar MLP frente a Perceptron se basa principalmente en la complejidad y distribucion de los datos. Ya que, MLP nos permite procesar datos aplicando funciones no lineales, mientras que Perceptron se limita segun que tan linealmente separados estan los datos. Si nuestro dataset llegase a no poder ser clasificado binariamente a partir del hiperplano que utiliza el algoritmo Perceptron, entonces puede ser el caso en que obtengamos resultados incorrectos o mal clasificados. Por otra parte, la capacidad predictiva de MLP es mas acertada que Perceptron. Esto se debe a que MLP actualiza los coeficientes pesos mediante el algoritmo __Back Propagation__, cuya finalidad es buscar el minimo valor de error a partir del calculo del gradiente descendente. En este caso, los pesos que minimicen la funcion de error seran parte de la solucion del problema de aprendizaje. En consecuencia, MLP mejora cada vez mas su prediccion dado a la minimizacion de la funcion de error. Mientras que Perceptron, en cada iteracion varia su prediccion de manera _aleatoria_. \n",
    "\n",
    "#### Referencias\n",
    "- [Towards Data Science - Multi-Layer Perceptron explained with a real example](https://towardsdatascience.com/multilayer-perceptron-explained-with-a-real-life-example-and-python-code-sentiment-analysis-cb408ee93141)\n",
    "- [Science Direct - Multi layer perceptron](https://www.sciencedirect.com/topics/computer-science/multilayer-perceptron)\n",
    "- [Medium - MLP Neural network algorithm and its components](https://medium.com/analytics-vidhya/multi-layer-perceptron-neural-network-algorithm-and-its-components-d3e997eb42bb)\n",
    "- [Baeldung - Hidden layers](https://www.baeldung.com/cs/hidden-layers-neural-network)\n",
    "- [University of New South Wales - BackPropagation Algorithm](https://www.cse.unsw.edu.au/~cs9417ml/MLP2/BackPropagation.html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Crear y entrenar el modelo (7 Pts.)\n",
    "Entrene un clasificador de MLP con los datos de `entrenamiento`. Tienes libertad para modificar los hiperpar치metros, cantidad de capas, neuronas, etc. Pero toda decisi칩n debe ser `justificada`. Recuerda que el objetivo es obtener el mejor modelo posible. Para justificar tus decisiones puedes experimentar, buscar documentaci칩n o lo que estimes conveniente.\n",
    "\n",
    "**Importante:** No se eval칰a que el modelo sea el mejor, si no que se justifiquen las decisiones tomadas. Es decir, no sirve de nada tener un porcentaje de acierto alto si no se justifica por qu칠 se lleg칩 a ese resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 886,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Utilizaremos una red neuronal con solo 1 capa oculta, con 16 neuronas y una capa de salida con 2 neuronas\n",
    "(la cantidad de clases que presentamos), ya que el dataset es 'peque침o' y evitamos un sobreajuste del modelo \n",
    "al definir muchas neuronas. Es decir, nos encontraremos entre tener una peor generalizacion y una mejor aproximacion. \n",
    "'''\n",
    "dense1 = Dense(16, activation='relu') # capa oculta con 10 neuronas y funcion de activacion relu\n",
    "dense2 = Dense(2, activation='softmax') # salida es un softmax\n",
    "model = Sequential(layers=[dense1, dense2]) # Definimos el modelo\n",
    "\n",
    "# Observacion: Ajuste a prueba y error con diferentes neuronas, y las predicciones mas altas entre todas las ejecuciones\n",
    "# ocurrieron con 16 neuronas en la capa oculta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 940,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compilamos el modelo con el optimizador adam, la funcion de perdida sparse_categorical_crossentropy (Entropia cruzada),\n",
    "# y la metrica accuracy (acierto)\n",
    "model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"]) \n",
    "\n",
    "# Observacion: Utilizamos el optimizador adam, ya que es un optimizador que se adapta a los datos. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 941,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilizamos la estrategia de entrenamiento EarlyStopping para evitar un sobreajuste del modelo. En este caso, \n",
    "# si la funcion de perdida no disminuye en 2 iteraciones sin mejoras, se detiene el entrenamiento.\n",
    "callback = EarlyStopping(monitor='loss', patience=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 946,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/18\n",
      "13/13 [==============================] - 1s 10ms/step - loss: 0.0866 - accuracy: 0.9670\n",
      "Epoch 2/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9695\n",
      "Epoch 3/18\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0865 - accuracy: 0.9746\n",
      "Epoch 4/18\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0858 - accuracy: 0.9695\n",
      "Epoch 5/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0860 - accuracy: 0.9721\n",
      "Epoch 6/18\n",
      "13/13 [==============================] - 0s 11ms/step - loss: 0.0853 - accuracy: 0.9746\n",
      "Epoch 7/18\n",
      "13/13 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9746\n",
      "Epoch 8/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0845 - accuracy: 0.9721\n",
      "Epoch 9/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9721\n",
      "Epoch 10/18\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9721\n",
      "Epoch 11/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9721\n",
      "Epoch 12/18\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.0839 - accuracy: 0.9746\n",
      "Epoch 13/18\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.0843 - accuracy: 0.9746\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2ff859ab0>"
      ]
     },
     "execution_count": 946,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finalmente entrenamos el modelo con 18 epocas (iteraciones de training) y \n",
    "# un batch_size de 32 (cantidad de datos entrenados por iteracion)\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=18, callbacks=[callback])\n",
    "\n",
    "# Fuimos configurando los parametros a prueba y error, en este caso el valor de \n",
    "# predicciones mas alto ocurrio con 18 epocas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Evaluar el modelo (2 Pts.)\n",
    "Eval칰e el modelo con los datos de `testing` y calcule `accuracy`, `precision`, `recall` y `f1-score`. Puedes apoyarte de un reporte de clasificaci칩n. Comenta todos los resultados y explica qu칠 significan 游."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los labels de las clases para ver el desempe침o de\n",
    "labels_classes = ['Benign tumor', 'Malignant tumor']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 953,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 8ms/step\n",
      "Test Accuracy : 0.9823529411764705\n",
      "\n",
      "Classification Report : \n",
      "                 precision    recall  f1-score   support\n",
      "\n",
      "   Benign tumor       0.99      0.98      0.99       103\n",
      "Malignant tumor       0.97      0.99      0.98        67\n",
      "\n",
      "       accuracy                           0.98       170\n",
      "      macro avg       0.98      0.98      0.98       170\n",
      "   weighted avg       0.98      0.98      0.98       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_preds = model.predict(X_test).argmax(axis=-1) # Obtenemos las predicciones del modelo\n",
    "print(\"Test Accuracy : {}\".format(accuracy_score(y_test, y_preds))) \n",
    "print(\"\\nClassification Report : \")\n",
    "print(classification_report(y_test, y_preds, target_names=labels_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "游녤游낕 Podemos observar que obtenemos un valor de _accuracy_ muy alto, cerca de un 98%. Esto implica que MLP es un modelo muy bueno para poder predecir tumores cancerigenos. Este nivel de acierto puede ser dado a la complejidad de MLP, ya que logramos alterar algunos parametros dentro del codigo para presentar la prediccion __mas__ acertada. \n",
    "\n",
    "游녤游낕 Dentro del __CLassification Report__ encontramos las definiciones de las siguientes medidas:\n",
    "0. __accuracy__: Mide la cantidad de verdaderos positivos y negativos con respecto al total de predicciones en terminos porcentuales.\n",
    "1. __precission__: Mide la cantidad de verdaderos positivos con respecto a la suma de verdaderos positivos y negativos. \n",
    "2. __recall__: Conocida como \"sensibilidad\". Mide la habilidad de un modelo en detectar posibles eventos correctos. \n",
    "3. __f1-score__: Se conoce como la media armonica de la precision y el recall. Ambas metricas (precission y recall) contribuyen equitativamente al valor de f1-score, asegurando que indique \"que tan acertadas\" son las predicciones realizadas por el modelo. \n",
    "4. __support__: Numero de muestras de cada clase. \n",
    "\n",
    "游녤游낕 A partir de los resultados de _Classification Report_, podemos decir que el modelo (utilizando imagenes digitalizadas) presenta un acierto de un 99% para diagnosticar tumores benignos, y un 97% para diagnosticar tumores malignos. En este sentido podemos decir que el modelo en si es un buen predictor de tumores cancerigenos, pero aun asi existe un 1% y 3% de error en la prediccion de tumores benignos y malignos, respectivamente. Esto es un grave problema, ya que probablemente existen casos de personas que se le diagnostican tumores benignos, pero en realidad son malignos. Por lo que, el modelo no es del todo __confiable__ aun cuando tiene un alto grado de certeza.\n",
    "\n",
    "游녤游낕 Por otra parte, en base al classification report, el modelo no esta balanceado equitativamente para los casos malignos y benignos, ya que presentamos muestras de 103 y 67 para Benigno y Maligno, respectivamente. Esto puede ser un factor que influye en la prediccion, ya que el modelo puede estar sesgado para predecir mas casos de tumores benignos que malignos.\n",
    "\n",
    "游녤游낕 Finalmente, podemos decir que el modelo MLP es un muy buen predictor para diagnosticar tumores cancerigenos. Dado que presenta un alto valor de f1-score, se puede afirmar que presenta una alta certeza en sus predicciones.  \n",
    "#### Referencias bibliograficas \n",
    "[Picsellia - Understanding F1 Score in ML](https://www.picsellia.com/post/understanding-the-f1-score-in-machine-learning-the-harmonic-mean-of-precision-and-recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Matriz de confusi칩n (6 Pts.)\n",
    "Genere una `matriz de confusi칩n` normalizada del modelo y responda las preguntas:\n",
    "1. 쯈u칠 significa cada fila de la matriz?\n",
    "2. 쯈u칠 significa cada columna de la matriz?\n",
    "3. Explique error `tipo I` y error `tipo II` en base a la matriz de confusi칩n.\n",
    "4. En relaci칩n al problema de c치ncer de mama, 쯤ue tipo error es m치s grave? 쯇or qu칠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 954,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Funcion para graficar la matriz de confusion (Referencia bibliografica: Actividad formativa 8)\n",
    "def plot_confusion_matrix(cm: np.ndarray, classes: np.ndarray,\n",
    "                          normalize: bool = False,\n",
    "                          title: str ='Confusion matrix',\n",
    "                          cmap:str = plt.cm.Greens):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_preds)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(5, 5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=labels_classes, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__쯈u칠 significa cada fila de la matriz?__\n",
    "\n",
    "游녤游낕 Cada fila de la matriz de confusion representa el numero de instancias de una clase especifica del dataset.\n",
    "\n",
    "__쯈u칠 significa cada columna de la matriz?__\n",
    "\n",
    "游녤游낕 Cada columna de la matriz de confusion indica la cantidad de instancias que el modelo ha predicho para cada clase, es decir, indica la clase predicha por el modelo. \n",
    "\n",
    "__Explique error `tipo I` y error `tipo II` en base a la matriz de confusi칩n.__\n",
    "\n",
    "游녤游낕 Por un lado, el **```error tipo I```**, o __falso positivo__, es cuando el modelo predice que la clase es positiva, pero en realidad el resultado real es negativo. Bajo el contexto del dataset, en este caso el __modelo predice__ que el 1% de las imagenes digitalizadas son tumores benignos, pero realmente son tumores malignos. Por otro lado, el __```error tipo II```__, o __falso negativo__, es cuando el modelo predice que la clase es negativa, pero el resultado real es positiva. Bajo el contexto del dataset, el modelo predice que el 2% de las imagenes digitalizadas son tumores malignos, pero en realidad son tumores benignos. \n",
    "\n",
    "__En relaci칩n al problema de c치ncer de mama, 쯤ue tipo error es m치s grave? 쯇or qu칠?__\n",
    "\n",
    "游녤游낕 En relacion al problema de cancer de mama, el error mas grave es el de tipo I. Ya que, en este caso existe un cierto porcentaje de las imagenes digitalizadas en donde el modelo esta afirmando que los tumores correspondientes son de tipo _benigno_, cuando el valor real es de tipo _maligno_. Este caso es muy grave, ya que en palabras simples el modelo esta creando diagnosticos falsos, y declarando a las personas libres de cancer, siendo que realmente estan desarrollando celulas cancerigenas que pueden terminar con su vida.\n",
    "El error de tipo II si bien es grave, pero bajo el contexto del dataset no es tan grave como el de tipo I. Este diagnostico falso indica que la persona tiene un tumor maligno enves de un tumor benigno, implicando posiblemente un gasto monetario en el proceso de erradicacion de las celulas cancerigenas. Este error puede atentar con la situacion economica de la persona, pero no atenta con la vida de esta. \n",
    "\n",
    "#### Referencias bibliograficas\n",
    "[JuanBarrios BIGDATA - Matriz de confusion](https://www.juanbarrios.com/la-matriz-de-confusion-y-sus-metricas/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 3: Regresi칩n Log칤stica (20 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Teor칤a Regresi칩n Log칤stica (10 pts)\n",
    "Al igual que con Perceptron, investiga sobre `Regresi칩n L칩gistica` y da una explicaci칩n con tus propias palabras de c칩mo funciona. Nuevamente no se espera una demostraci칩n matem치tica, el objetivo es que demuestres tu aprendizaje. Puedes apoyarte de las siguientes preguntas gu칤a: 쯈u칠 es? 쯈u칠 tipo de problemas resuelve? 쮺칩mo se calcula la probabilidad? 쯈u칠 funci칩n de activaci칩n utiliza? 쯈u칠 se busca durante el proceso de entrenamiento? 쯈u칠 son los coeficientes? 쮺칩mo se toma la decisi칩n final de clasificaci칩n? 쮺u치l es la relaci칩n con la regresi칩n lineal? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**쯈u칠 es?**\n",
    "\n",
    "游녤游낕 Regresion logistica es una estrategia estadistica que implementa un algoritmo de clasificacion binaria sobre un set de datos para predecir probabilisticamente la pertenencia de cada dato con respecto a alguna variable categorica. \n",
    "\n",
    "**쯈u칠 tipo de problemas resuelve?** \n",
    "\n",
    "游녤游낕 Tiene como objetivo resolver problemas de clasificacion binaria. Ademas, Es una tecnica altamente recomendada para el analisis de datos, ya que se puede implementar con el fin de predecir eventos mediante probabilidades. Es usado para predecir variables categorias dependientes usando un conjunto de variables independientes. Por otra parte, tambien resuelve problemas de la evaluacion de modelos de prediccion, evaluando el rendimiento de este con las medidas _accuracy_, _precission_, _recall_ y _f1-score_.\n",
    "\n",
    "**쮺칩mo se calcula la probabilidad?** \n",
    "\n",
    "游녤游낕 Definamos $\\textbf{x}$ y $\\textbf{w}$ como el vector del conjunto de caracteristicas y el de los pesos de entradas (parametro del modelo), respectivamente, dentro de un espacio d-dimensional. \n",
    "$$\\textbf{w} = \\begin{bmatrix}w_0 \\\\ w_1 \\\\ \\vdots \\\\ w_d\\end{bmatrix}\\in\\mathbb{R}^{d+1} \\hspace{1cm} \\textbf{x} = \\begin{bmatrix}1 \\\\ x_1 \\\\ \\vdots \\\\ x_d\\end{bmatrix} \\in {1} \\times \\mathbb{R}^d$$\n",
    "Para poder calcular la probabilidad de prediccion, Regresion logistica utiliza la funcion _sigmoid_ para transformar la sumatoria de las combinacion lineal $\\textbf{w}^T\\textbf{x}$ dentro de un dominio cerrado, tal que asi nos permite obtener la prediccion en terminos probabilisticos. En este sentido, podemos definir $s = \\textbf{w}^T\\textbf{x}$ y la funcion de _sigmoid_ como:\n",
    "$$\\theta(s) = \\frac{1}{1+e^{-s}}$$\n",
    "en donde $\\theta(s)$ solo se mueve entre 0 y 1.\n",
    "\n",
    "<div style=\"text-align:center\"><img src=\"https://media.geeksforgeeks.org/wp-content/uploads/20190522162153/sigmoid-function-300x138.png\"></div>\n",
    "\n",
    "**쯈u칠 funci칩n de activaci칩n utiliza?** \n",
    "\n",
    "游녤游낕 La funcion de activacion que utiliza la tecnica regresion logistica es la funcion logistica _sigmoid function_, en donde la suma de las combinaciones lineales entre cada caracteristica con un peso respectivo se transmiten a traves de esta funcion de activacion, y posteriormente esta determina un valor binario de 0 o 1, clasificando los datos. \n",
    "\n",
    "**쯈u칠 se busca durante el proceso de entrenamiento?** \n",
    "\n",
    "游녤游낕 Durante el proceso de entrenamiento se busca el rendimiento del modelo a partir de la determinacion de los parametros del modelo, es decir, se tiene como objetivo buscar los parametros que \"maximizan\" la precision del modelo sobre la variable objetivo categorica, evaluando tanto su nivel de acierto y clasificacion. \n",
    "\n",
    "**쯈u칠 son los coeficientes?** \n",
    "\n",
    "游녤游낕 Dentro del contexto del modelo de regresion logistica, determinamos la probabilidad de que una variable objetivo pertenezca a una categoria especifica (clasificacion binaria). Cada variable esta asociada a un coeficiente (o peso), en donde cada peso asignado puede tomar un valor positivo o negativo. Los coeficientes son los parametros estimados del modelo de regresion logistica. El valor de este parametro depende de la \"relevancia\" que presenta cada variable, por lo que se ajusta segun _la magnitud que  aporta_ la variable dentro de la prediccion del modelo. \n",
    "\n",
    "**쮺칩mo se toma la decisi칩n final de clasificaci칩n?** \n",
    "\n",
    "游녤游낕 La decision final de clasificacion se determina en base al valor que toma la funcion de activacion. Esta clasificacion binaria se realiza de la siguiente manera. Por ejemplo, dado un set de imagenes, queremos clasificar las imagenes que contienen un arbol y las que no, es decir, si la probabilidad es mas cercana a 1 y sobre o igual a 0.5, entonces la imagen contiene un arbol. Mientras que si la probabilidad es mas cercana a 0 y menor a 0.5, entonces la imagen no contiene un arbol. Esta logica de clasificacion binaria implementa el modelo de regresion logistica para decidir la asignaci칩n de cada dato con respecto a una variable categorica. En este sentido, si el valor retornado de la funcion es mas cercano a 1 (y mayor o igual a 0.5), entonces el objeto a clasificar presenta una mayor probabilidad de ser clasificado correctamente (por ejemplo, como un arbol). En el caso contrario, si el valor retornado es mas cercano a 0 y menor a 0.5, entonces el objeto no es clasificado como un arbol. \n",
    "\n",
    "**쮺u치l es la relaci칩n con la regresi칩n lineal?** \n",
    "\n",
    "游녤游낕 La relacion entre el modelo de regresion lineal y logistica recae en que ambos modelos determinan un valor de prediccion basado en variables independientes. La diferencia se presenta en que la regresion lineal es utilizado para predecir una variable continua, mientras que la regresion logistica es utilizado para predecir una variable categorica. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Crear y entrenar el modelo (3 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea y entrena un modelo de regresion logistica con los datos de entrenamiento, donde a traves del parametro `solver`, deberas elegir minimo 3 opciones diferentes de algoritmos de optimizacion, responder `cuales son sus principales diferencias` respecto a como actualizan los parametros del modelo y `dar una hipotesis` sobre cual crees que sera el algoritmo que funcione mejor para este dataset. Recuerda que la idea es que `justifiques tu respuesta`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "游녤游낕 Para este ejemplo escogeremos los siguientes algoritmos de optimizacion: ```liblinear```, ```sag```, y ```newton-cg```. Por un lado, liblinear (Large Linear Classification) es un clasificador linear para datos con millones de instancias y caracteristicas. Es eficiente para datasets peque침os. Por otro lado, SAG es un algoritmo de gradiente estocastico promedio. Es eficiente para datasets grandes. Y finalmente, newton-cg es un algoritmo que utiliza el metodo Newton-Conjugado para encontrar el minimo de una funcion objetivo. Se considera como un buen algoritmo para un dataaset grande, suele ser mas lento pero preciso, y suele ser eficiente para un dataset con una cantidad ajustada de caracteristicas. \n",
    "\n",
    "游녤游낕 Creo que el algoritmo que mejor funcionaria podria en primer lugar *newton-cg*. El dataset presenta una cantidad de datos \"moderada\" o mediana, ya que contiene aproximadamente 500 filas y 30 columnas, implicando que el algoritmo de optimizacion que presente una mayor eficiencia pueda ser *newton-cg*, ya que este suele ser utilizado para datasets grandes. Por otro lado, no considero que el dataset sea peque침o, por lo que liblinear dudo que presente mayor eficiencia que los otros 2 algoritmos. Finalmente, SAG tambien puede ser un algoritmo eficiente, ya que tambien esta destinado para ser utilizado en datasets grandes, siendo mi segundo candidato. \n",
    "\n",
    "\n",
    "#### Referencias bibliograficas \n",
    "- [Liblinear](https://www.csie.ntu.edu.tw/~cjlin/liblinear/)\n",
    "- [SAG](https://inria.hal.science/hal-00860051/document)\n",
    "- [Newton-CG](https://link.springer.com/article/10.1007/s10107-019-01362-7)\n",
    "- [Solvers](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 893,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers = ['liblinear', 'sag', 'newton-cg']\n",
    "\n",
    "clf_1 = LogisticRegression(solver='liblinear')\n",
    "clf_1.fit(X_train, y_train)\n",
    "\n",
    "clf_2 = LogisticRegression(solver='sag')\n",
    "clf_2.fit(X_train, y_train)\n",
    "\n",
    "clf_3 = LogisticRegression(solver='newton-cg')\n",
    "clf_3.fit(X_train, y_train)\n",
    "\n",
    "clfs = [clf_1, clf_2, clf_3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Evaluar el modelo (2 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para `cada uno` de los tres modelos anteriores, evalua el modelo con los datos de testing y calcula `accuracy`, `precision`, `recall` y `f1-score`. Puedes apoyarte de un reporte de clasificaci칩n. Comenta todos los resultados y explica qu칠 significan 游."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 894,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************ liblinear *************************\n",
      "                 Score: 0.9411764705882353                  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.93      0.97      0.95       103\n",
      "         1.0       0.95      0.90      0.92        67\n",
      "\n",
      "    accuracy                           0.94       170\n",
      "   macro avg       0.94      0.93      0.94       170\n",
      "weighted avg       0.94      0.94      0.94       170\n",
      "\n",
      "*************************** sag ****************************\n",
      "                 Score: 0.9529411764705882                  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       103\n",
      "         1.0       0.97      0.91      0.94        67\n",
      "\n",
      "    accuracy                           0.95       170\n",
      "   macro avg       0.96      0.95      0.95       170\n",
      "weighted avg       0.95      0.95      0.95       170\n",
      "\n",
      "************************ newton-cg *************************\n",
      "                 Score: 0.9529411764705882                  \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.98      0.96       103\n",
      "         1.0       0.97      0.91      0.94        67\n",
      "\n",
      "    accuracy                           0.95       170\n",
      "   macro avg       0.96      0.95      0.95       170\n",
      "weighted avg       0.95      0.95      0.95       170\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index, clf in enumerate(clfs):\n",
    "    print(f\" {solvers[index]} \".center(60, \"*\"))\n",
    "    print(f'Score: {clf.score(X_test, y_test)}'.center(60))\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando las definiciones de Precission, Recall, F1-Score y Support en el item 2.3 ... \n",
    "\n",
    "游녤游낕 En primer lugar, podemos visualizar que todos los algoritmos utilizados presentaron una precision similar. Dado el resultado de classification report, logramos comprobar nuestra hipotesis. En este caso, podemos ver que tanto SAG como Newton-CG presentaron un mismo score. Esto puede ser por que como habiamos dicho, el dataset se considera de tama침o mediano, por lo que estos algoritmos probablemente sean mas eficiente que liblineal, cuyo rendimiento es eficiente para datasets peque침os. \n",
    "\n",
    "游녤游낕 En segundo lugar, podemos visualizar que en todos los casos la precision del modelo de regresion lineal es alta, presentando un valor sobre un 90%. \n",
    "\n",
    "游녤游낕 Tanto el valor de recall como de f1-score tambien estan sobre el 90%. Por lo tanto, podemos decir que el modelo tiene una alta capacidad en poder acertar eventos positivos, y cada prediccion tiene un alto grado de certeza.\n",
    "\n",
    "游녤游낕 Finalmente, podemos decir que el modelo de regresion logistica no esta bien balanceado, ya que presenta una muestra de 103 para casos benignos y 67 para malignos. Esto puede influir en la certeza de las predicciones realizadas por el modelo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Matriz de confusi칩n (5 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De los modelos elegidos previamente, escoja el que mejor funcione y genere una `matriz de confusi칩n` del modelo y responda la siguiente pregunta:\n",
    "\n",
    "1. 쯈ue tan grave es el error que tenemos segun la matriz de confusi칩n en el problema de c치ncer de mama? 쯇or qu칠?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 895,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 898,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = clf_3.predict(X_test) # Escogemos Newton-CG dado que presento un mejor desempe침o (al igual que SAG)\n",
    "\n",
    "cnf_matrix = confusion_matrix(y_test, y_pred)\n",
    "np.set_printoptions(precision=2)\n",
    "\n",
    "classes = np.unique(y)\n",
    "\n",
    "# Plot normalized confusion matrix\n",
    "plt.figure(figsize=(5,5))\n",
    "plot_confusion_matrix(cnf_matrix, classes=classes, normalize=True, title='Normalized confusion matrix')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__쯈ue tan grave es el error que tenemos segun la matriz de confusi칩n en el problema de c치ncer de mama? 쯇or qu칠?__\n",
    "\n",
    "游녤游낕 Tal como mencionamos en la matriz de confusion del modelo MLP, para el modelo de regresion logistica ocurre el mismo caso. Podemos visualizar que existe un alto porcentaje (9%) de imagenes digitalizadas que fueron predichas por parte del modelo por presentar un tumor benigno, siendo que en realidad el tumor es maligno. Este error es muy grave, ya que para este modelo presentamos una mayor cantidad de porcentaje de imagenes que fueron diagnosticadas con tumores benignos cuando no correspondian, es decir, el modelo realizo diagnosticos falsos.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parte 4: Comparaci칩n de Modelos (5 Pts.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Comparaci칩n de modelos (5 Pts.)\n",
    "Una vez implementado cada modelo con los datos, compara los resultados obtenidos.\n",
    "1. __쯈ue modelo posee el mejor `rendimiento` en este caso? 쯇or qu칠?__\n",
    "\n",
    "游녤游낕 Si hablamos en terminos de los valores de precision y f1-score, el modelo Multi Layer Perceptron presento un mejor rendimiento que el modelo de regresion logistica. Ya que, principalmente presento un accuracy mas alto, y con respecto a la matriz de confusion, presento un menor porcentaje de **falsos positivos**. En consecuencia, podemos decir que el modelo MLP es menos propenso a realizar diagnosticos \"falsos\", y  presenta un mayor grado de certeza en sus predicciones. \n",
    "\n",
    "2. __쯈u칠 m칠tricas se utilizaron para comparar los modelos?__\n",
    "\n",
    "Las metricas que principalmente utilice para comparar ambos modelos fueron accuracy y f1-score. Como podemos visualizar en los Classification Reports, en el caso del modelo MLP, este presenta un mayor grado de precision, y su f1-score es de un 99 y 98%, para casos benignos y malignos respectivamente. Mientras que el modelo de regresion logistica presento un grado de precision mas bajo que MLP (aproximadamente entre un 2% a 3% de precision menos) y su f1-score es de un 96% y 94% para casos benignos y malignos,  respectivamente. En consecuencia podemos decir que el modelo MLP presenta una mejor capacidad predictiva que el modelo de regresion logistica al momento de clasificar imagenes digitalizadas con tumores malignos y benignos. \n",
    "\n",
    "3. __쯈u칠 ventajas y desventajas tiene cada modelo?__\n",
    "\n",
    "Por un lado, las ventajas que presenta el modelo MLP es que tiene mayor nivel de certeza que el modelo Regresion Logistica. Como al ser una coleccion de perceptrones, permite aplicar funciones no lineales que podrian aprender mejor en datos que probablemente no son linealmente separables. Sin embargo, uno de los aspectos que creo que podria ser una desventaja es que los resultados de accuracy pueden varian segun los parametros que uno condicione. Por ejemplo, durante el calculo de la precision y la formacion de la matriz de confusion para el modelo MLP, los resultados eran muy variados segun los valores asignados para la cantidad de neuornas en la capa oculta, el ```batch_size```, y la cantidad de ```epochs```. A \"prueba y error\" fui asignando los valores e inicialmente los valores de accuracy me daban entre 80% y 85%. Esto es dado que MLP es un modelo \"adaptable\" para resolver problemas complejos en donde se pueden necesitar muchas neuronas (y probablemente mas capas) para tomar una decision final. Es por ello, que se tuvo que buscar un valor optimo de los parametros con respecto a la dimension de nuestro dataset para esperar un mejor valor en las predicciones. \n",
    "\n",
    "Por otro lado, las ventajas que presenta el modelo de regresion logistica es que es eficiente al momento de entrenar y es facil de implementar para problemas que requieren clasificar datos en dos posibles categorias. Al igual que Perceptron, Regresion lineal funciona bien cuando los datos son linealmente separables. En consecuencia, esto limita la toma de decisiones para este modelo  cuando los problemas no son lineales, ya que regresion logistica tambien presenta una superficie de decision lineal. \n",
    "\n",
    "4. __쮼n que casos es mejor utilizar un modelo que otro? 쯇or qu칠?__\n",
    "\n",
    "La eleccion de que cada modelo antes que otros depende segun diferentes aspectos: \n",
    "\n",
    "__a) Regresion logistica__: \n",
    "- Este modelo rinde mejor que MLP cuando necesitamos realizar una clasificacion binaria de los datos en 2 posibles variables categoricas, considerando que los datos son linealmente separables. Este modelo presenta mas eficiencia que MLP al momento de clasificar binariamente en el caso de que se presente un data set una baja complejidad, ya que puede evitar el sobreajuste de los datos de entrenamiento. Al momento de entrenar el modelo MLP, la cantidad de neuronas a utilizar afecta los resultados. En este sentido, a mayor cantidad de neuronas, tiene una menor capacidad de generalizacion, por lo que no podria realizar predicciones precisas. \n",
    "\n",
    "\n",
    "__b) Multi Layer Perceptron__: \n",
    "- Este modelo rinde mejor que Regresion logistica cuando necesitamos realizar problemas de clasificacion para datos que no son linealmente separabbles. Presenta mejor rendimiento cuando nos encontramos con un dataset con una gran cantidad de datos y caracteristicas (mas complejo). Asismismo, MLP presenta mayor universalidad y adaptabilidad en diferentes problemas, mas all치 que clasificacion binaria. Este puede ser implementado en otros problemas, como por ejemmplo clasificar noticias a partir del texto que presentan (considerando que el set de datos es grande). Esto requiere mayor complejidad de aprendizaje, y MLP presenta mejor capacidad predictiva que regresion logistica. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
