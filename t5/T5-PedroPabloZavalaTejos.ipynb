{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3B6kdIC0A8j"
      },
      "source": [
        "Pontificia Universidad Católica de Chile <br>\n",
        "Departamento de Ciencia de la Computación <br>\n",
        "IIC2433 - Minería de Datos\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "    <h2> Tarea 5 </h2>\n",
        "    <h1> SVM </h1>\n",
        "    <p>\n",
        "        Profesor Marcelo Mendoza<br>\n",
        "        Segundo Semestre 2023<br> \n",
        "        Fecha de entrega: 3 de noviembre\n",
        "    </p>\n",
        "    <br>\n",
        "</center>\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4hXVuL2Lv-"
      },
      "source": [
        "## Indicaciones\n",
        "\n",
        "Deberás entregar **SOLO** el archivo .ipynb en el buzón respectivo en canvas.\n",
        "\n",
        "**IMPORTANTE**:\n",
        "- Se te dará puntaje tanto por código como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un código perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendrá el puntaje completo.\n",
        "- El notebook debe tener todas las celdas de código ejecutadas. Cualquier notebook que no las tenga no podrá ser corregido.\n",
        "- El carácter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultará en un 1,1 como nota de curso.\n",
        "- En el caso de que se encuentren con problemas al correr celdas por el tamaño del dataset, esta permitido trabajar con una muestra representativa de este, siempre explicitando y justificando sus deciciones.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D20JLCp2NQy"
      },
      "source": [
        "## Librerías"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jxFL6JoZ2k9D"
      },
      "outputs": [],
      "source": [
        "##Importa acá las librerias que vayas a utilizar\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "\n",
        "# from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contexto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se tiene un dataset con información de distintas noticias, entre las cuales hay noticias falsas y verdaderas. El objetivo de esta tarea es predecir si una noticia es falsa o verdadera, utilizando distintos modelos de clasificación.. Para esto, primero se debe hacer un análisis exploratorio de los datos para decidir qué variables son relevantes para el problema. Luego, se debe vectorizar el texto de loas noticias para poder utilizarlo en un modelo de clasificación (en esta tarea usaremos SBert y TF-IDF). Después se debe entrenar un modelo de clasificación SVM que prediga si una noticia es falsa o verdadera. Finalmente, se debe evaluar el modelo y compararlo con otros modelos de clasificación."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objetivos de la tarea:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Realizar un análisis exploratorio de datos para determinar las variables pertinentes para el problema en cuestión, identificando características clave y patrones en los datos que podrían afectar la clasificación de las noticias.\n",
        "- Dominar la técnica de vectorización de texto para facilitar su aplicación en un modelo de clasificación, y comprender la interpretación de los resultados obtenidos.\n",
        "- Entender el funcionamiento de un modelo de clasificación SVM y sus hiperparámetros.\n",
        "- Entrenar un modelo de clasificación SVM capaz de predecir si una noticia es falsa o verdadera.\n",
        "- Evaluar el desempeño del modelo y analizar en profundidad los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwvXdDO36uO"
      },
      "source": [
        "# Parte 1: Carga y Preprocesamiento (10 puntos)\n",
        "\n",
        "## 1.1 Carga de datos (1 punto)\n",
        "\n",
        "Para esta tarea deberás trabajar con el dataset que está en Canvas, 'news.csv'. Este dataset contiene información de distintas noticias, entre las cuales hay noticias falsas y verdaderas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year’...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama’s Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>U.S. Agriculture secretary nominee submits eth...</td>\n",
              "      <td>(Reuters) - U.S. President Donald Trump’s nomi...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Trump aides attack agency that will analyze he...</td>\n",
              "      <td>WASHINGTON (Reuters) - Aides to U.S. President...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 12, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Highlights: The Trump presidency on March 12 a...</td>\n",
              "      <td>(Reuters) - Highlights of the day for U.S. Pre...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 12, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Obama lawyers move fast to join fight against ...</td>\n",
              "      <td>WASHINGTON (Reuters) - When Johnathan Smith re...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Mike Pence to tour Asia next month amid securi...</td>\n",
              "      <td>JAKARTA (Reuters) - U.S. Vice President Mike P...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0      Donald Trump Sends Out Embarrassing New Year’...   \n",
              "1      Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2      Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3      Trump Is So Obsessed He Even Has Obama’s Name...   \n",
              "4      Pope Francis Just Called Out Donald Trump Dur...   \n",
              "...                                                 ...   \n",
              "9995  U.S. Agriculture secretary nominee submits eth...   \n",
              "9996  Trump aides attack agency that will analyze he...   \n",
              "9997  Highlights: The Trump presidency on March 12 a...   \n",
              "9998  Obama lawyers move fast to join fight against ...   \n",
              "9999  Mike Pence to tour Asia next month amid securi...   \n",
              "\n",
              "                                                   text       subject  \\\n",
              "0     Donald Trump just couldn t wish all Americans ...          News   \n",
              "1     House Intelligence Committee Chairman Devin Nu...          News   \n",
              "2     On Friday, it was revealed that former Milwauk...          News   \n",
              "3     On Christmas day, Donald Trump announced that ...          News   \n",
              "4     Pope Francis used his annual Christmas Day mes...          News   \n",
              "...                                                 ...           ...   \n",
              "9995  (Reuters) - U.S. President Donald Trump’s nomi...  politicsNews   \n",
              "9996  WASHINGTON (Reuters) - Aides to U.S. President...  politicsNews   \n",
              "9997  (Reuters) - Highlights of the day for U.S. Pre...  politicsNews   \n",
              "9998  WASHINGTON (Reuters) - When Johnathan Smith re...  politicsNews   \n",
              "9999  JAKARTA (Reuters) - U.S. Vice President Mike P...  politicsNews   \n",
              "\n",
              "                   date authenticity  \n",
              "0     December 31, 2017         Fake  \n",
              "1     December 31, 2017         Fake  \n",
              "2     December 30, 2017         Fake  \n",
              "3     December 29, 2017         Fake  \n",
              "4     December 25, 2017         Fake  \n",
              "...                 ...          ...  \n",
              "9995    March 13, 2017          Real  \n",
              "9996    March 12, 2017          Real  \n",
              "9997    March 12, 2017          Real  \n",
              "9998    March 13, 2017          Real  \n",
              "9999    March 13, 2017          Real  \n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('news.csv', sep=',')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['News', 'politicsNews'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['subject'].unique() # Verificamos cuantas categorias presenta el data set en terminos del tipo de noticia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjqBcwhUGa2j"
      },
      "source": [
        "## 1.2 Descripcion del Dataset (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptkeso4_NZbp"
      },
      "source": [
        "\n",
        "\n",
        "¿Qué representa cada feature en el dataset entregado? Refiérete a su tipo de dato, detallando cómo trabajar con los datos no númericos (2 puntos)\n",
        "\n",
        "RESPUESTA:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "👉🏻 A partir de los atributos visualiazdos en el set de datos, podemos verificar que todas las variables son de tipo texto, excepto date que es de tipo fecha. \n",
        "* ```title```: Representa el titulo de la noticia. Es una variable categorica nominal, ya que no representa un orden propuesto dentro de la tabulacion.  \n",
        "* ```texto```: Representa el contexto de la noticia. Es una variable categorica nominal. \n",
        "Como title y texts no son variables numericas, para poder trabajarlas realizaremos un preprocesamiento el cual consistira en eliminar las palabras comunes \n",
        "y luego utilizar algun lematizador para poder reducir las cadenas de oraciones a su forma base, es decir, reducirlas a su raiz semántica, eliminando \n",
        "prefijos y sufijos. Esto nos permitira reducir la complejidad en cada tupla y analizar comparativamente con el resto del set de datos .\n",
        "* ```date```: Representa la fecha en la cual la noticia fue publicada. Como no es un dato numerico, podemos transformarlo a de tipo numerico para su posterior analisis utilizando \n",
        "el valor en representacion \"Unix Time\". Unix time convierte la fecha actual en la cantidad de segundos desde el primer dia del año. En este sentido, trabajaremos con fechas en segundos \n",
        "para poder compararlos con los otros datos y mejorar analisis. \n",
        "* ```Subject```: Representa el tema relatado en la noticia. En este caso corresponde a una variable categorica nominal. Podemos visualizar que solo contiene dos categorias: News y PolitcNews. En el caso de news representa a un reporte general de un suceso, mientras que PoliticNews esta determinado dentro del contexto de la politica. Por lo tanto, podemos transformar esta caracteristica a una variable numerica binaria: 0 si es News y 1 si es politicNews.  \n",
        "* ```Authenticity```: Representa que tan veridico es la noticia. Es una variable categorica nominal. Presenta dos resultados (Fake/Real). Por lo tanto, podemos trabajar esta variable como una variable binaria. Donde 0 es para el caso de que sea Fake, y 1 si es Real. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JSFOZ7lRzA5"
      },
      "source": [
        "¿Qué columnas o features crees son relevantes para el problema? ¿Por qué? (3 puntos)\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "👉🏻 Por un lado, la variable de respuesta para poder predecir si la noticia es verdadera o falsa sera la columna __authenticity__. Ya que, nos permitiria verificar el rendimiento de nuestro modelo con respecto a los valores reales. Por otro lado, tanto el titulo como el texto nos permitiran verificar a que clase corresponde la noticia, ya que al tener las palabras claves de la noticia nos permitirá clasificar segun el tema que esta referencia. Nos permitirá comparar los resultados entre si y obtener un mejor grado de prediccion. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeCYvsCyRXUU"
      },
      "source": [
        "## 1.3 Datos nulos (2 puntos)\n",
        "\n",
        "Analiza la presencia de valores nulos en el conjunto de datos y cómo se distribuyen en las distintas columnas. Después, toma una decisión acerca del tratamiento adecuado para el dataframe con respecto a los valores nulos. Justifica tu decisión.\n",
        "\n",
        "RESPUESTA:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, text, subject, date, authenticity]\n",
              "Index: []"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[data.isnull().any(axis=1)] # Al verificar la presencia de datos nulos, podemos visualizar que no existen "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhm6ZjBnRix7"
      },
      "source": [
        "## 1.4 Manejo del Dataset (2 puntos)\n",
        "\n",
        "- Elimina las columnas que no sean relevantes para el entrenamiento del modelo (1 pts.)\n",
        "- Haz que los textos estén en un formato óptimo para ser procesados por los modelos de clasificación (0.5 pts.) Justifica tu decisión (0.5 pts.)\n",
        "\n",
        "\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# En primer lugar, eliminaremos la columna the date, ya que consideraremos que no es relevante para la prediccion de la vericidad de las noticias\n",
        "data.drop(columns=['date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Luego transformaremos las caracteristicas authenticity y subject a tipo binaria\n",
        "# News = 0, politicsNews = 1\n",
        "# Fake = 0, Real = 1\n",
        "data['subject'] = data['subject'].replace('News', 0)\n",
        "data['subject'] = data['subject'].replace('politicsNews', 1)\n",
        "data['authenticity'] = data['authenticity'].replace('Fake', 0)\n",
        "data['authenticity'] = data['authenticity'].replace('Real', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finalmente, defininiremos la funcion tokenize para que conserve las palabras elementales de cada fila (reducir cada palabra a su raiz semantica). \n",
        "stop_words = set(stopwords.words('english')) # Eliminamos stop words como and, the, etc ... \n",
        "tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')  \n",
        "lemmatizer = WordNetLemmatizer() # Inicializamos el Lematizador\n",
        "def tokenize(document):\n",
        "    words = []\n",
        "    for sentence in sent_tokenize(document):\n",
        "        tokens = [lemmatizer.lemmatize(t.lower()) for t in tokenizer.tokenize(sentence) if t.lower() not in stop_words and len(t) > 2]\n",
        "        words += tokens\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['text'] = data['text'].apply(tokenize) # Aplicamos tokenize para cada fila de la columna text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['title'] = data['title'].apply(tokenize) # Aplicamos tokenize para cada fila de la columna text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>donald trump sends embarrassing new year eve m...</td>\n",
              "      <td>donald trump wish american happy new year leav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drunk bragging trump staffer started russian c...</td>\n",
              "      <td>house intelligence committee chairman devin nu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sheriff david clarke becomes internet joke thr...</td>\n",
              "      <td>friday revealed former milwaukee sheriff david...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trump obsessed even obama name coded website i...</td>\n",
              "      <td>christmas day donald trump announced would bac...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pope francis called donald trump christmas speech</td>\n",
              "      <td>pope francis used annual christmas day message...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>agriculture secretary nominee submits ethic di...</td>\n",
              "      <td>reuters president donald trump nominee head ag...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>trump aide attack agency analyze health bill's...</td>\n",
              "      <td>washington reuters aide president donald trump...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>highlight trump presidency march est</td>\n",
              "      <td>reuters highlight day president donald trump a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>obama lawyer move fast join fight trump</td>\n",
              "      <td>washington reuters johnathan smith resigned ju...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>mike penny tour asia next month amid security ...</td>\n",
              "      <td>jakarta reuters vice president mike penny visi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     donald trump sends embarrassing new year eve m...   \n",
              "1     drunk bragging trump staffer started russian c...   \n",
              "2     sheriff david clarke becomes internet joke thr...   \n",
              "3     trump obsessed even obama name coded website i...   \n",
              "4     pope francis called donald trump christmas speech   \n",
              "...                                                 ...   \n",
              "9995  agriculture secretary nominee submits ethic di...   \n",
              "9996  trump aide attack agency analyze health bill's...   \n",
              "9997               highlight trump presidency march est   \n",
              "9998            obama lawyer move fast join fight trump   \n",
              "9999  mike penny tour asia next month amid security ...   \n",
              "\n",
              "                                                   text  subject  authenticity  \n",
              "0     donald trump wish american happy new year leav...        0             0  \n",
              "1     house intelligence committee chairman devin nu...        0             0  \n",
              "2     friday revealed former milwaukee sheriff david...        0             0  \n",
              "3     christmas day donald trump announced would bac...        0             0  \n",
              "4     pope francis used annual christmas day message...        0             0  \n",
              "...                                                 ...      ...           ...  \n",
              "9995  reuters president donald trump nominee head ag...        1             1  \n",
              "9996  washington reuters aide president donald trump...        1             1  \n",
              "9997  reuters highlight day president donald trump a...        1             1  \n",
              "9998  washington reuters johnathan smith resigned ju...        1             1  \n",
              "9999  jakarta reuters vice president mike penny visi...        1             1  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data # Podemos visualizar que cada texto, tanto para title como text, las palabras estan reducidas a su raiz semantica y en minúscula. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "👉🏻 Tener las columnas title y text reducidos de tal manera nos permitira preprocesar mejor los datos, luego de ser vectorizados, podremos predecir con mayor acierto en la autenticidad de la noticia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 2: Vectorización (14 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SBert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar SBert para vectorizar los textos de las noticias. Utilicen el modelo pre-entrenado de SBert llamado SentenceTransformer. Específicamente, deben usar el modelo 'paraphrase-MiniLM-L6-v2' para obtener las representaciones vectoriales de las oraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1) Vectorización con SBert (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 Análisis teórico de SBert (4 puntos)\n",
        "Responde las siguientes preguntas: ¿Qué es SBert? ¿Cómo funciona? ¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__¿Qué es SBert?__ \n",
        "\n",
        "👉🏻 \n",
        "\n",
        "__¿Cómo funciona?__  \n",
        "\n",
        "👉🏻 \n",
        "\n",
        "__¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?__\n",
        "\n",
        "👉🏻"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar TF-IDF para vectorizar los textos de las noticias. Utilicen la clase TfidfVectorizer de la librería sklearn.\n",
        "\n",
        "\n",
        "Tip: limita la cantidad de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3) Vectorización con TF-IDF (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2) Análisis teórico de TF-IDF (4 puntos)\n",
        "Responde las siguientes preguntas: ¿Qué es TF-IDF? ¿Cómo funciona? ¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?\n",
        "\n",
        "RESPUESTA:\n",
        "\n",
        "__¿Qué es TF-IDF?__\n",
        "\n",
        "👉🏻\n",
        "\n",
        "__¿Cómo funciona?__\n",
        "\n",
        "👉🏻\n",
        "\n",
        "__¿Qué ventajas y desventajas tiene sobre otros modelos de vectorización de texto?__\n",
        "\n",
        "👉🏻\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVspTAuVGsUM"
      },
      "source": [
        "# Parte 3: SVM (36 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1) Preguntas teóricas (10 puntos)\n",
        "1. ¿Qué es SVM? ¿Cómo funciona? ¿En qué casos es útil? ¿En cuáles no? (4 ptos.)\n",
        "3. ¿Qué es un kernel? ¿Qué tipos de kernels existen? ¿Cuál es la diferencia entre ellos? (3 ptos.)\n",
        "4. ¿Qué indica el parámetro C? ¿Qué sucede si C es muy grande? ¿Y si es muy pequeño? (3 ptos.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2) SVM con vectorización SBert (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con SBert. Deben utilizar la clase SVC de la librería sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperparámetros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3) SVM con vectorización TF-IDF (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con TF-IDF. Deben utilizar la clase SVC de la librería sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperparámetros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4) Análisis de resultados (6 puntos)\n",
        "- ¿Qué vectorización obtuvo mejores resultados, SBert o TF-IDF? ¿Por qué? (3 ptos.)\n",
        "- ¿Qué hiperparámetros obtuvieron mejores resultados para cada vectorización? (3 ptos.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 4 (Bonus): LIME explainer (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuación haz un análisis de los resultados obtenidos con el modelo SVM con vectorización SBert utilizando LIME explainer. Para esto, debes seguir los siguientes pasos:\n",
        "- Instalar la librería Lime\n",
        "- Elegir un ejemplo de test\n",
        "- Utilizar el explainer de Lime para explicar la predicción del modelo en ese ejemplo (2.5 pts.)\n",
        "- Analizar los resultados obtenidos y comentar brevemente (2.5 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
