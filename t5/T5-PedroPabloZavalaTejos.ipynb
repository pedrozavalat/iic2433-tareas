{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V3B6kdIC0A8j"
      },
      "source": [
        "Pontificia Universidad Cat√≥lica de Chile <br>\n",
        "Departamento de Ciencia de la Computaci√≥n <br>\n",
        "IIC2433 - Miner√≠a de Datos\n",
        "<br>\n",
        "\n",
        "<center>\n",
        "    <h2> Tarea 5 </h2>\n",
        "    <h1> SVM </h1>\n",
        "    <p>\n",
        "        Profesor Marcelo Mendoza<br>\n",
        "        Segundo Semestre 2023<br> \n",
        "        Fecha de entrega: 3 de noviembre\n",
        "    </p>\n",
        "    <br>\n",
        "</center>\n",
        "\n",
        "<br>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cx4hXVuL2Lv-"
      },
      "source": [
        "## Indicaciones\n",
        "\n",
        "Deber√°s entregar **SOLO** el archivo .ipynb en el buz√≥n respectivo en canvas.\n",
        "\n",
        "**IMPORTANTE**:\n",
        "- Se te dar√° puntaje tanto por c√≥digo como por la manera en la que respondas las preguntas planteadas. Es decir, si tienes un c√≥digo perfecto pero este no es explicado o no se responden preguntas asociadas a este, no se tendr√° el puntaje completo.\n",
        "- El notebook debe tener todas las celdas de c√≥digo ejecutadas. Cualquier notebook que no las tenga no podr√° ser corregido.\n",
        "- El car√°cter de esta tarea es **INDIVIDUAL**. Cualquier instancia de copia resultar√° en un 1,1 como nota de curso.\n",
        "- En el caso de que se encuentren con problemas al correr celdas por el tama√±o del dataset, esta permitido trabajar con una muestra representativa de este, siempre explicitando y justificando sus deciciones.\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0D20JLCp2NQy"
      },
      "source": [
        "## Librer√≠as"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "jxFL6JoZ2k9D"
      },
      "outputs": [],
      "source": [
        "##Importa ac√° las librerias que vayas a utilizar\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import RegexpTokenizer, sent_tokenize\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import numpy as np\n",
        "\n",
        "# from lime.lime_text import LimeTextExplainer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Contexto:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Se tiene un dataset con informaci√≥n de distintas noticias, entre las cuales hay noticias falsas y verdaderas. El objetivo de esta tarea es predecir si una noticia es falsa o verdadera, utilizando distintos modelos de clasificaci√≥n.. Para esto, primero se debe hacer un an√°lisis exploratorio de los datos para decidir qu√© variables son relevantes para el problema. Luego, se debe vectorizar el texto de loas noticias para poder utilizarlo en un modelo de clasificaci√≥n (en esta tarea usaremos SBert y TF-IDF). Despu√©s se debe entrenar un modelo de clasificaci√≥n SVM que prediga si una noticia es falsa o verdadera. Finalmente, se debe evaluar el modelo y compararlo con otros modelos de clasificaci√≥n."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Objetivos de la tarea:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "- Realizar un an√°lisis exploratorio de datos para determinar las variables pertinentes para el problema en cuesti√≥n, identificando caracter√≠sticas clave y patrones en los datos que podr√≠an afectar la clasificaci√≥n de las noticias.\n",
        "- Dominar la t√©cnica de vectorizaci√≥n de texto para facilitar su aplicaci√≥n en un modelo de clasificaci√≥n, y comprender la interpretaci√≥n de los resultados obtenidos.\n",
        "- Entender el funcionamiento de un modelo de clasificaci√≥n SVM y sus hiperpar√°metros.\n",
        "- Entrenar un modelo de clasificaci√≥n SVM capaz de predecir si una noticia es falsa o verdadera.\n",
        "- Evaluar el desempe√±o del modelo y analizar en profundidad los resultados obtenidos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aAwvXdDO36uO"
      },
      "source": [
        "# Parte 1: Carga y Preprocesamiento (10 puntos)\n",
        "\n",
        "## 1.1 Carga de datos (1 punto)\n",
        "\n",
        "Para esta tarea deber√°s trabajar con el dataset que est√° en Canvas, 'news.csv'. Este dataset contiene informaci√≥n de distintas noticias, entre las cuales hay noticias falsas y verdaderas."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Donald Trump Sends Out Embarrassing New Year‚Äô...</td>\n",
              "      <td>Donald Trump just couldn t wish all Americans ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Drunk Bragging Trump Staffer Started Russian ...</td>\n",
              "      <td>House Intelligence Committee Chairman Devin Nu...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 31, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Sheriff David Clarke Becomes An Internet Joke...</td>\n",
              "      <td>On Friday, it was revealed that former Milwauk...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 30, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Trump Is So Obsessed He Even Has Obama‚Äôs Name...</td>\n",
              "      <td>On Christmas day, Donald Trump announced that ...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 29, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Pope Francis Just Called Out Donald Trump Dur...</td>\n",
              "      <td>Pope Francis used his annual Christmas Day mes...</td>\n",
              "      <td>News</td>\n",
              "      <td>December 25, 2017</td>\n",
              "      <td>Fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>U.S. Agriculture secretary nominee submits eth...</td>\n",
              "      <td>(Reuters) - U.S. President Donald Trump‚Äôs nomi...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>Trump aides attack agency that will analyze he...</td>\n",
              "      <td>WASHINGTON (Reuters) - Aides to U.S. President...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 12, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>Highlights: The Trump presidency on March 12 a...</td>\n",
              "      <td>(Reuters) - Highlights of the day for U.S. Pre...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 12, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>Obama lawyers move fast to join fight against ...</td>\n",
              "      <td>WASHINGTON (Reuters) - When Johnathan Smith re...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>Mike Pence to tour Asia next month amid securi...</td>\n",
              "      <td>JAKARTA (Reuters) - U.S. Vice President Mike P...</td>\n",
              "      <td>politicsNews</td>\n",
              "      <td>March 13, 2017</td>\n",
              "      <td>Real</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows √ó 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0      Donald Trump Sends Out Embarrassing New Year‚Äô...   \n",
              "1      Drunk Bragging Trump Staffer Started Russian ...   \n",
              "2      Sheriff David Clarke Becomes An Internet Joke...   \n",
              "3      Trump Is So Obsessed He Even Has Obama‚Äôs Name...   \n",
              "4      Pope Francis Just Called Out Donald Trump Dur...   \n",
              "...                                                 ...   \n",
              "9995  U.S. Agriculture secretary nominee submits eth...   \n",
              "9996  Trump aides attack agency that will analyze he...   \n",
              "9997  Highlights: The Trump presidency on March 12 a...   \n",
              "9998  Obama lawyers move fast to join fight against ...   \n",
              "9999  Mike Pence to tour Asia next month amid securi...   \n",
              "\n",
              "                                                   text       subject  \\\n",
              "0     Donald Trump just couldn t wish all Americans ...          News   \n",
              "1     House Intelligence Committee Chairman Devin Nu...          News   \n",
              "2     On Friday, it was revealed that former Milwauk...          News   \n",
              "3     On Christmas day, Donald Trump announced that ...          News   \n",
              "4     Pope Francis used his annual Christmas Day mes...          News   \n",
              "...                                                 ...           ...   \n",
              "9995  (Reuters) - U.S. President Donald Trump‚Äôs nomi...  politicsNews   \n",
              "9996  WASHINGTON (Reuters) - Aides to U.S. President...  politicsNews   \n",
              "9997  (Reuters) - Highlights of the day for U.S. Pre...  politicsNews   \n",
              "9998  WASHINGTON (Reuters) - When Johnathan Smith re...  politicsNews   \n",
              "9999  JAKARTA (Reuters) - U.S. Vice President Mike P...  politicsNews   \n",
              "\n",
              "                   date authenticity  \n",
              "0     December 31, 2017         Fake  \n",
              "1     December 31, 2017         Fake  \n",
              "2     December 30, 2017         Fake  \n",
              "3     December 29, 2017         Fake  \n",
              "4     December 25, 2017         Fake  \n",
              "...                 ...          ...  \n",
              "9995    March 13, 2017          Real  \n",
              "9996    March 12, 2017          Real  \n",
              "9997    March 12, 2017          Real  \n",
              "9998    March 13, 2017          Real  \n",
              "9999    March 13, 2017          Real  \n",
              "\n",
              "[10000 rows x 5 columns]"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data = pd.read_csv('news.csv', sep=',')\n",
        "data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array(['News', 'politicsNews'], dtype=object)"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data['subject'].unique() # Verificamos cuantas categorias presenta el data set en terminos del tipo de noticia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjqBcwhUGa2j"
      },
      "source": [
        "## 1.2 Descripcion del Dataset (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptkeso4_NZbp"
      },
      "source": [
        "\n",
        "\n",
        "¬øQu√© representa cada feature en el dataset entregado? Refi√©rete a su tipo de dato, detallando c√≥mo trabajar con los datos no n√∫mericos (2 puntos)\n",
        "\n",
        "RESPUESTA:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üëâüèª A partir de los atributos visualiazdos en el set de datos, podemos verificar que todas las variables son de tipo texto, excepto date que es de tipo fecha. \n",
        "* ```title```: Representa el titulo de la noticia. Es una variable categorica nominal, ya que no representa un orden propuesto dentro de la tabulacion.  \n",
        "* ```texto```: Representa el contexto de la noticia. Es una variable categorica nominal. \n",
        "Como title y texts no son variables numericas, para poder trabajarlas realizaremos un preprocesamiento el cual consistira en eliminar las palabras comunes \n",
        "y luego utilizar algun lematizador para poder reducir las cadenas de oraciones a su forma base, es decir, reducirlas a su raiz sem√°ntica, eliminando \n",
        "prefijos y sufijos. Esto nos permitira reducir la complejidad en cada tupla y analizar comparativamente con el resto del set de datos .\n",
        "* ```date```: Representa la fecha en la cual la noticia fue publicada. Como no es un dato numerico, podemos transformarlo a de tipo numerico para su posterior analisis utilizando \n",
        "el valor en representacion \"Unix Time\". Unix time convierte la fecha actual en la cantidad de segundos desde el primer dia del a√±o. En este sentido, trabajaremos con fechas en segundos \n",
        "para poder compararlos con los otros datos y mejorar analisis. \n",
        "* ```Subject```: Representa el tema relatado en la noticia. En este caso corresponde a una variable categorica nominal. Podemos visualizar que solo contiene dos categorias: News y PolitcNews. En el caso de news representa a un reporte general de un suceso, mientras que PoliticNews esta determinado dentro del contexto de la politica. Por lo tanto, podemos transformar esta caracteristica a una variable numerica binaria: 0 si es News y 1 si es politicNews.  \n",
        "* ```Authenticity```: Representa que tan veridico es la noticia. Es una variable categorica nominal. Presenta dos resultados (Fake/Real). Por lo tanto, podemos trabajar esta variable como una variable binaria. Donde 0 es para el caso de que sea Fake, y 1 si es Real. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JSFOZ7lRzA5"
      },
      "source": [
        "¬øQu√© columnas o features crees son relevantes para el problema? ¬øPor qu√©? (3 puntos)\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üëâüèª Por un lado, la variable de respuesta para poder predecir si la noticia es verdadera o falsa sera la columna __authenticity__. Ya que, nos permitiria verificar el rendimiento de nuestro modelo con respecto a los valores reales. Por otro lado, tanto el titulo como el texto nos permitiran verificar a que clase corresponde la noticia, ya que al tener las palabras claves de la noticia nos permitir√° clasificar segun el tema que esta referencia. Nos permitir√° comparar los resultados entre si y obtener un mejor grado de prediccion. \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YeCYvsCyRXUU"
      },
      "source": [
        "## 1.3 Datos nulos (2 puntos)\n",
        "\n",
        "Analiza la presencia de valores nulos en el conjunto de datos y c√≥mo se distribuyen en las distintas columnas. Despu√©s, toma una decisi√≥n acerca del tratamiento adecuado para el dataframe con respecto a los valores nulos. Justifica tu decisi√≥n.\n",
        "\n",
        "RESPUESTA:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>date</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [title, text, subject, date, authenticity]\n",
              "Index: []"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data[data.isnull().any(axis=1)] # Al verificar la presencia de datos nulos, podemos visualizar que no existen "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yhm6ZjBnRix7"
      },
      "source": [
        "## 1.4 Manejo del Dataset (2 puntos)\n",
        "\n",
        "- Elimina las columnas que no sean relevantes para el entrenamiento del modelo (1 pts.)\n",
        "- Haz que los textos est√©n en un formato √≥ptimo para ser procesados por los modelos de clasificaci√≥n (0.5 pts.) Justifica tu decisi√≥n (0.5 pts.)\n",
        "\n",
        "\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [],
      "source": [
        "# En primer lugar, eliminaremos la columna the date, ya que consideraremos que no es relevante para la prediccion de la vericidad de las noticias\n",
        "data.drop(columns=['date'], inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Luego transformaremos las caracteristicas authenticity y subject a tipo binaria\n",
        "# News = 0, politicsNews = 1\n",
        "# Fake = 0, Real = 1\n",
        "data['subject'] = data['subject'].replace('News', 0)\n",
        "data['subject'] = data['subject'].replace('politicsNews', 1)\n",
        "data['authenticity'] = data['authenticity'].replace('Fake', 0)\n",
        "data['authenticity'] = data['authenticity'].replace('Real', 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Finalmente, defininiremos la funcion tokenize para que conserve las palabras elementales de cada fila (reducir cada palabra a su raiz semantica). \n",
        "stop_words = set(stopwords.words('english')) # Eliminamos stop words como and, the, etc ... \n",
        "tokenizer = RegexpTokenizer('[\\'a-zA-Z]+')  \n",
        "lemmatizer = WordNetLemmatizer() # Inicializamos el Lematizador\n",
        "def tokenize(document):\n",
        "    words = []\n",
        "    for sentence in sent_tokenize(document):\n",
        "        tokens = [lemmatizer.lemmatize(t.lower()) for t in tokenizer.tokenize(sentence) if t.lower() not in stop_words and len(t) > 2]\n",
        "        words += tokens\n",
        "    text = ' '.join(words)\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['text'] = data['text'].apply(tokenize) # Aplicamos tokenize para cada fila de la columna text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "data['title'] = data['title'].apply(tokenize) # Aplicamos tokenize para cada fila de la columna text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>subject</th>\n",
              "      <th>authenticity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>donald trump sends embarrassing new year eve m...</td>\n",
              "      <td>donald trump wish american happy new year leav...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drunk bragging trump staffer started russian c...</td>\n",
              "      <td>house intelligence committee chairman devin nu...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sheriff david clarke becomes internet joke thr...</td>\n",
              "      <td>friday revealed former milwaukee sheriff david...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>trump obsessed even obama name coded website i...</td>\n",
              "      <td>christmas day donald trump announced would bac...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>pope francis called donald trump christmas speech</td>\n",
              "      <td>pope francis used annual christmas day message...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9995</th>\n",
              "      <td>agriculture secretary nominee submits ethic di...</td>\n",
              "      <td>reuters president donald trump nominee head ag...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9996</th>\n",
              "      <td>trump aide attack agency analyze health bill's...</td>\n",
              "      <td>washington reuters aide president donald trump...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9997</th>\n",
              "      <td>highlight trump presidency march est</td>\n",
              "      <td>reuters highlight day president donald trump a...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9998</th>\n",
              "      <td>obama lawyer move fast join fight trump</td>\n",
              "      <td>washington reuters johnathan smith resigned ju...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999</th>\n",
              "      <td>mike penny tour asia next month amid security ...</td>\n",
              "      <td>jakarta reuters vice president mike penny visi...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000 rows √ó 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  title  \\\n",
              "0     donald trump sends embarrassing new year eve m...   \n",
              "1     drunk bragging trump staffer started russian c...   \n",
              "2     sheriff david clarke becomes internet joke thr...   \n",
              "3     trump obsessed even obama name coded website i...   \n",
              "4     pope francis called donald trump christmas speech   \n",
              "...                                                 ...   \n",
              "9995  agriculture secretary nominee submits ethic di...   \n",
              "9996  trump aide attack agency analyze health bill's...   \n",
              "9997               highlight trump presidency march est   \n",
              "9998            obama lawyer move fast join fight trump   \n",
              "9999  mike penny tour asia next month amid security ...   \n",
              "\n",
              "                                                   text  subject  authenticity  \n",
              "0     donald trump wish american happy new year leav...        0             0  \n",
              "1     house intelligence committee chairman devin nu...        0             0  \n",
              "2     friday revealed former milwaukee sheriff david...        0             0  \n",
              "3     christmas day donald trump announced would bac...        0             0  \n",
              "4     pope francis used annual christmas day message...        0             0  \n",
              "...                                                 ...      ...           ...  \n",
              "9995  reuters president donald trump nominee head ag...        1             1  \n",
              "9996  washington reuters aide president donald trump...        1             1  \n",
              "9997  reuters highlight day president donald trump a...        1             1  \n",
              "9998  washington reuters johnathan smith resigned ju...        1             1  \n",
              "9999  jakarta reuters vice president mike penny visi...        1             1  \n",
              "\n",
              "[10000 rows x 4 columns]"
            ]
          },
          "execution_count": 47,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "data # Podemos visualizar que cada texto, tanto para title como text, las palabras estan reducidas a su raiz semantica y en min√∫scula. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "üëâüèª Tener las columnas title y text reducidos de tal manera nos permitira preprocesar mejor los datos, luego de ser vectorizados, podremos predecir con mayor acierto en la autenticidad de la noticia. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 2: Vectorizaci√≥n (14 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# SBert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar SBert para vectorizar los textos de las noticias. Utilicen el modelo pre-entrenado de SBert llamado SentenceTransformer. Espec√≠ficamente, deben usar el modelo 'paraphrase-MiniLM-L6-v2' para obtener las representaciones vectoriales de las oraciones."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.1) Vectorizaci√≥n con SBert (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2 An√°lisis te√≥rico de SBert (4 puntos)\n",
        "Responde las siguientes preguntas: ¬øQu√© es SBert? ¬øC√≥mo funciona? ¬øQu√© ventajas y desventajas tiene sobre otros modelos de vectorizaci√≥n de texto?\n",
        "\n",
        "RESPUESTA:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "__¬øQu√© es SBert?__ \n",
        "\n",
        "üëâüèª \n",
        "\n",
        "__¬øC√≥mo funciona?__  \n",
        "\n",
        "üëâüèª \n",
        "\n",
        "__¬øQu√© ventajas y desventajas tiene sobre otros modelos de vectorizaci√≥n de texto?__\n",
        "\n",
        "üëâüèª"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# TF-IDF"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Para esta parte, deben utilizar TF-IDF para vectorizar los textos de las noticias. Utilicen la clase TfidfVectorizer de la librer√≠a sklearn.\n",
        "\n",
        "\n",
        "Tip: limita la cantidad de features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.3) Vectorizaci√≥n con TF-IDF (3 puntos)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2.2) An√°lisis te√≥rico de TF-IDF (4 puntos)\n",
        "Responde las siguientes preguntas: ¬øQu√© es TF-IDF? ¬øC√≥mo funciona? ¬øQu√© ventajas y desventajas tiene sobre otros modelos de vectorizaci√≥n de texto?\n",
        "\n",
        "RESPUESTA:\n",
        "\n",
        "__¬øQu√© es TF-IDF?__\n",
        "\n",
        "üëâüèª\n",
        "\n",
        "__¬øC√≥mo funciona?__\n",
        "\n",
        "üëâüèª\n",
        "\n",
        "__¬øQu√© ventajas y desventajas tiene sobre otros modelos de vectorizaci√≥n de texto?__\n",
        "\n",
        "üëâüèª\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVspTAuVGsUM"
      },
      "source": [
        "# Parte 3: SVM (36 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.1) Preguntas te√≥ricas (10 puntos)\n",
        "1. ¬øQu√© es SVM? ¬øC√≥mo funciona? ¬øEn qu√© casos es √∫til? ¬øEn cu√°les no? (4 ptos.)\n",
        "3. ¬øQu√© es un kernel? ¬øQu√© tipos de kernels existen? ¬øCu√°l es la diferencia entre ellos? (3 ptos.)\n",
        "4. ¬øQu√© indica el par√°metro C? ¬øQu√© sucede si C es muy grande? ¬øY si es muy peque√±o? (3 ptos.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.2) SVM con vectorizaci√≥n SBert (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con SBert. Deben utilizar la clase SVC de la librer√≠a sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperpar√°metros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.3) SVM con vectorizaci√≥n TF-IDF (10 puntos) \n",
        "Para esta parte deben entrenar un modelo SVM con las representaciones vectoriales obtenidas con TF-IDF. Deben utilizar la clase SVC de la librer√≠a sklearn. Para esto:\n",
        "- Deben dejar los datos en un formato adecuado para ser procesados por el modelo (1 pto.)\n",
        "- Dividir el dataset en train y test (1 pto.)\n",
        "- Entrenar el modelo SVM con los datos de train (2 ptos.) modificando los hiperpar√°metros kernel y C (4 ptos.)\n",
        "- Evaluar el modelo con los datos de test y comentar brevemente los resultados obtenidos (2 ptos.)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3.4) An√°lisis de resultados (6 puntos)\n",
        "- ¬øQu√© vectorizaci√≥n obtuvo mejores resultados, SBert o TF-IDF? ¬øPor qu√©? (3 ptos.)\n",
        "- ¬øQu√© hiperpar√°metros obtuvieron mejores resultados para cada vectorizaci√≥n? (3 ptos.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Parte 4 (Bonus): LIME explainer (5 puntos)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "A continuaci√≥n haz un an√°lisis de los resultados obtenidos con el modelo SVM con vectorizaci√≥n SBert utilizando LIME explainer. Para esto, debes seguir los siguientes pasos:\n",
        "- Instalar la librer√≠a Lime\n",
        "- Elegir un ejemplo de test\n",
        "- Utilizar el explainer de Lime para explicar la predicci√≥n del modelo en ese ejemplo (2.5 pts.)\n",
        "- Analizar los resultados obtenidos y comentar brevemente (2.5 pts.)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
